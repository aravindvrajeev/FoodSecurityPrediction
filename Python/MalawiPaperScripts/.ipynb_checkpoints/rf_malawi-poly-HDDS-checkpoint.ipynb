{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Notebook\n",
    "% matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "labels = ['clust_logFCS', 'clust_RCSI', 'clust_HDDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clust_L12raincytot</th>\n",
       "      <th>clust_L12day1rain</th>\n",
       "      <th>clust_L12maxdays</th>\n",
       "      <th>clust_floodmax</th>\n",
       "      <th>clust_cells_own</th>\n",
       "      <th>clust_price</th>\n",
       "      <th>clust_thinn</th>\n",
       "      <th>clust_roof</th>\n",
       "      <th>clust_hhsize</th>\n",
       "      <th>clust_hh_age</th>\n",
       "      <th>clust_hh_gender</th>\n",
       "      <th>clust_asset</th>\n",
       "      <th>clust_dist_road</th>\n",
       "      <th>clust_dist_admarc</th>\n",
       "      <th>clust_percent_ag</th>\n",
       "      <th>clust_nutri_reten_constrained</th>\n",
       "      <th>clust_elevation</th>\n",
       "      <th>ipc_lag1</th>\n",
       "      <th>ipc_lag12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1090.06130</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>3.824215</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>5.4375</td>\n",
       "      <td>41.6250</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>-0.327686</td>\n",
       "      <td>1.395625</td>\n",
       "      <td>5.176875</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1311.8750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>855.86176</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>3.917409</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>5.6875</td>\n",
       "      <td>36.5625</td>\n",
       "      <td>1.3125</td>\n",
       "      <td>-0.202549</td>\n",
       "      <td>0.756875</td>\n",
       "      <td>5.408750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>496.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300.24370</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>3.683867</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>6.3750</td>\n",
       "      <td>40.4375</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>0.548275</td>\n",
       "      <td>0.163125</td>\n",
       "      <td>17.038126</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>526.7500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1036.97120</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>4.061391</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>5.4375</td>\n",
       "      <td>46.8750</td>\n",
       "      <td>1.1875</td>\n",
       "      <td>-0.077412</td>\n",
       "      <td>5.803750</td>\n",
       "      <td>7.724375</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>564.1875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>952.18280</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>3.879500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>43.8125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.202549</td>\n",
       "      <td>11.286875</td>\n",
       "      <td>11.103125</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1539.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clust_L12raincytot  clust_L12day1rain  clust_L12maxdays  clust_floodmax  \\\n",
       "0          1090.06130                 43                17             0.0   \n",
       "1           855.86176                 58                40             0.0   \n",
       "2          1300.24370                 53                29             0.0   \n",
       "3          1036.97120                 52                29             0.0   \n",
       "4           952.18280                 54                25             0.0   \n",
       "\n",
       "   clust_cells_own  clust_price  clust_thinn  clust_roof  clust_hhsize  \\\n",
       "0           0.1250     3.824215     0.359375      0.1250        5.4375   \n",
       "1           0.4375     3.917409     0.250000      0.1875        5.6875   \n",
       "2           1.5000     3.683867     0.250000      0.5000        6.3750   \n",
       "3           0.6250     4.061391     0.500000      0.2500        5.4375   \n",
       "4           0.5625     3.879500     0.250000      0.0625        7.0000   \n",
       "\n",
       "   clust_hh_age  clust_hh_gender  clust_asset  clust_dist_road  \\\n",
       "0       41.6250           1.2500    -0.327686         1.395625   \n",
       "1       36.5625           1.3125    -0.202549         0.756875   \n",
       "2       40.4375           1.3750     0.548275         0.163125   \n",
       "3       46.8750           1.1875    -0.077412         5.803750   \n",
       "4       43.8125           1.0000    -0.202549        11.286875   \n",
       "\n",
       "   clust_dist_admarc  clust_percent_ag  clust_nutri_reten_constrained  \\\n",
       "0           5.176875            0.6000                         0.0000   \n",
       "1           5.408750            0.6000                         0.9375   \n",
       "2          17.038126            0.4500                         1.0000   \n",
       "3           7.724375            0.4375                         0.0000   \n",
       "4          11.103125            0.4875                         1.0000   \n",
       "\n",
       "   clust_elevation  ipc_lag1  ipc_lag12  \n",
       "0        1311.8750       1.0        NaN  \n",
       "1         496.0000       1.0        NaN  \n",
       "2         526.7500       1.0        NaN  \n",
       "3         564.1875       1.0        NaN  \n",
       "4        1539.9375       1.0        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=train_data.drop(labels, axis=1)\n",
    "x_train = x_train.drop(x_train.columns[0], axis=1)\n",
    "x_test=test_data.drop(labels, axis=1)\n",
    "x_test = x_test.drop(x_test.columns[0], axis=1)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clust_logFCS</th>\n",
       "      <th>clust_RCSI</th>\n",
       "      <th>clust_HDDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.666015</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>4.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.718879</td>\n",
       "      <td>5.352941</td>\n",
       "      <td>5.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.799830</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>5.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.844891</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>5.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.687936</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clust_logFCS  clust_RCSI  clust_HDDS\n",
       "0      3.666015   12.312500    4.687500\n",
       "1      3.718879    5.352941    5.235294\n",
       "2      3.799830    5.080000    5.720000\n",
       "3      3.844891    4.285714    5.095238\n",
       "4      3.687936    0.812500    5.312500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_data[labels]\n",
    "y_test = test_data[labels]\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer,StandardScaler\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0, copy=False)\n",
    "x_train = imp.fit_transform(x_train)\n",
    "x_test = imp.fit_transform(x_test)\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "x_train = poly.fit_transform(x_train)\n",
    "x_test =  poly.fit_transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29157328215968636"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create and fit our linear regression model to training data\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(x_train, y_train[labels[2]])\n",
    "\n",
    "# Compute model predictions for test data\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_linear = stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6326097409989042"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on logFCS \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create Regressor with default properties\n",
    "rfc = RandomForestRegressor(random_state =0,n_jobs =4,warm_start = True)\n",
    "\n",
    "parameters = {'max_depth':np.arange( 1,4, 1 ).tolist(), 'min_samples_leaf':np.arange( 1, 4, 1 ).tolist()}\n",
    "clf = GridSearchCV(rfc, parameters,cv=6, n_jobs= 4, iid = True,  refit= True,pre_dispatch= '2*n_jobs')\n",
    "clf.fit(x_train, y_train[labels[2]])\n",
    "\n",
    "# Fit estimator and display score\n",
    "\n",
    "# Regress on test data\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_rfc = stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6473430686792643"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on logFCS \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create Regressor with default properties\n",
    "rfc = RandomForestRegressor(random_state =0,n_jobs =4,warm_start = True,max_depth=4, min_samples_leaf=5 )\n",
    "\n",
    "rfc.fit(x_train, y_train[labels[2]])\n",
    "# Fit estimator and display score\n",
    "\n",
    "# Regress on test data\n",
    "pred = rfc.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_rfc = stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236000039039707"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "ridge = RidgeCV(alphas=(400,800), fit_intercept=True, normalize=False, scoring=None, cv=5, gcv_mode='auto', store_cv_values=False) \n",
    "\n",
    "# Define different alpha values for different fits\n",
    "# alpha = [0.0, 1E-6, 1E-4, 1E-2, 1.0]\n",
    "\n",
    "ridge.fit(x_train, y_train[labels[2]])\n",
    "pred = ridge.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_ridge= stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246000099317235"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "bridge = BayesianRidge(alpha_1=30, alpha_2=70,lambda_1=0.01, compute_score=True)\n",
    "bridge.fit(x_train, y_train[labels[2]])\n",
    "pred = bridge.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_bridge= stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687626368972859"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "ls = LassoCV(eps=0.001, n_alphas=100, alphas=(0.01, 2), fit_intercept=True,precompute='auto',n_jobs=4, random_state=0, selection='cyclic')\n",
    "\n",
    "ls = ls.fit(x_train, y_train[labels[2]])\n",
    "pred = ls.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_ls= stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6836678406828095"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "en = ElasticNetCV(alphas=(0.1,0.02,3,2), copy_X=True, cv=10, eps=0.004, fit_intercept=True,\n",
    "       l1_ratio=0.33, max_iter=1000, n_alphas=100, n_jobs=1,\n",
    "       normalize=False, positive=False, precompute='auto', random_state=0,\n",
    "       selection='cyclic', tol=0.0001, verbose=0)\n",
    "\n",
    "en.fit(x_train, y_train[labels[2]])\n",
    "\n",
    "pred = en.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_en= stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6639836307166467"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create Regressor with default properties\n",
    "gbr = GradientBoostingRegressor(random_state=0,learning_rate=0.1, n_estimators=19,subsample=1, criterion='friedman_mse', min_samples_split=3)\n",
    "\n",
    "gbr.fit(x_train, y_train[labels[2]])\n",
    "pred = gbr.predict(x_test)\n",
    "\n",
    "actual = y_test[labels[2]]\n",
    "r2_gbr= stats.pearsonr(actual, pred)[0] ** 2\n",
    "r2_gbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(actual)\n",
    "df[\"pred\"] = pred\n",
    "df.to_csv('hddsplot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clust_HDDS</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.687500</td>\n",
       "      <td>4.724105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.235294</td>\n",
       "      <td>5.036210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.720000</td>\n",
       "      <td>5.740496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.095238</td>\n",
       "      <td>4.761530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.312500</td>\n",
       "      <td>4.997085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.421053</td>\n",
       "      <td>5.203568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.260870</td>\n",
       "      <td>4.856672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.650000</td>\n",
       "      <td>4.888986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.318182</td>\n",
       "      <td>4.648327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.125000</td>\n",
       "      <td>5.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.925926</td>\n",
       "      <td>4.933973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.095238</td>\n",
       "      <td>4.677065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.590909</td>\n",
       "      <td>4.746180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.190476</td>\n",
       "      <td>4.691899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.388889</td>\n",
       "      <td>5.351569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.714286</td>\n",
       "      <td>5.046278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.250000</td>\n",
       "      <td>5.860092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.755365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.181818</td>\n",
       "      <td>4.852406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.850000</td>\n",
       "      <td>5.098959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.584927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.650000</td>\n",
       "      <td>5.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.727272</td>\n",
       "      <td>5.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.263158</td>\n",
       "      <td>4.800111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.166666</td>\n",
       "      <td>5.273816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.368421</td>\n",
       "      <td>5.021356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.812500</td>\n",
       "      <td>4.871682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.157895</td>\n",
       "      <td>5.409004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.705882</td>\n",
       "      <td>4.997328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.035163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>5.300000</td>\n",
       "      <td>5.083175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5.055555</td>\n",
       "      <td>5.106551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>5.210527</td>\n",
       "      <td>4.725778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>5.650000</td>\n",
       "      <td>5.127534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>5.294118</td>\n",
       "      <td>4.804226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.571650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>4.863637</td>\n",
       "      <td>4.505086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>4.333334</td>\n",
       "      <td>4.517278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>5.652174</td>\n",
       "      <td>5.244330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>5.470588</td>\n",
       "      <td>4.759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>6.629630</td>\n",
       "      <td>6.410239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>6.100000</td>\n",
       "      <td>6.171575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>5.647059</td>\n",
       "      <td>5.246283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>5.727272</td>\n",
       "      <td>5.205746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4.875000</td>\n",
       "      <td>4.606697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5.571429</td>\n",
       "      <td>5.071089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>5.227272</td>\n",
       "      <td>4.387003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>5.400000</td>\n",
       "      <td>4.779647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>5.625000</td>\n",
       "      <td>5.049884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>5.571429</td>\n",
       "      <td>4.886232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>5.526316</td>\n",
       "      <td>5.091905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5.866667</td>\n",
       "      <td>5.430995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.333334</td>\n",
       "      <td>5.076389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>5.125000</td>\n",
       "      <td>4.736016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>5.388889</td>\n",
       "      <td>4.897282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>6.263158</td>\n",
       "      <td>5.609232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>6.333334</td>\n",
       "      <td>6.023755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6.409091</td>\n",
       "      <td>6.153259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>6.600000</td>\n",
       "      <td>5.865186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>6.789473</td>\n",
       "      <td>6.503606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clust_HDDS      pred\n",
       "0      4.687500  4.724105\n",
       "1      5.235294  5.036210\n",
       "2      5.720000  5.740496\n",
       "3      5.095238  4.761530\n",
       "4      5.312500  4.997085\n",
       "5      5.421053  5.203568\n",
       "6      5.260870  4.856672\n",
       "7      5.650000  4.888986\n",
       "8      5.318182  4.648327\n",
       "9      5.125000  5.141421\n",
       "10     4.925926  4.933973\n",
       "11     4.095238  4.677065\n",
       "12     4.590909  4.746180\n",
       "13     5.190476  4.691899\n",
       "14     5.388889  5.351569\n",
       "15     5.714286  5.046278\n",
       "16     6.250000  5.860092\n",
       "17     6.000000  5.755365\n",
       "18     5.181818  4.852406\n",
       "19     4.850000  5.098959\n",
       "20     4.650000  4.584927\n",
       "21     5.650000  5.047436\n",
       "22     5.727272  5.106700\n",
       "23     5.263158  4.800111\n",
       "24     6.166666  5.273816\n",
       "25     5.368421  5.021356\n",
       "26     5.812500  4.871682\n",
       "27     6.157895  5.409004\n",
       "28     5.705882  4.997328\n",
       "29     6.500000  6.035163\n",
       "..          ...       ...\n",
       "174    5.300000  5.083175\n",
       "175    5.055555  5.106551\n",
       "176    5.210527  4.725778\n",
       "177    5.650000  5.127534\n",
       "178    5.294118  4.804226\n",
       "179    4.625000  4.571650\n",
       "180    4.863637  4.505086\n",
       "181    4.333334  4.517278\n",
       "182    5.652174  5.244330\n",
       "183    5.470588  4.759200\n",
       "184    6.629630  6.410239\n",
       "185    6.100000  6.171575\n",
       "186    5.647059  5.246283\n",
       "187    5.727272  5.205746\n",
       "188    4.875000  4.606697\n",
       "189    5.571429  5.071089\n",
       "190    5.227272  4.387003\n",
       "191    5.400000  4.779647\n",
       "192    5.625000  5.049884\n",
       "193    5.571429  4.886232\n",
       "194    5.526316  5.091905\n",
       "195    5.866667  5.430995\n",
       "196    5.333334  5.076389\n",
       "197    5.125000  4.736016\n",
       "198    5.388889  4.897282\n",
       "199    6.263158  5.609232\n",
       "200    6.333334  6.023755\n",
       "201    6.409091  6.153259\n",
       "202    6.600000  5.865186\n",
       "203    6.789473  6.503606\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
