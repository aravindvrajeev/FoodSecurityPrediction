{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Copy of Predict_FS_MW_EDA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "z4-7F9HoPcQq",
        "s7DXM1k9N2nt",
        "Iw6L0fotmdJk"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhou100/FoodSecurityPrediction/blob/master/Predict_FS_recall_smote.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M84u2C8HfggW"
      },
      "source": [
        "# Use machine learning to predict food security"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I19oMdkdgy5O",
        "colab": {}
      },
      "source": [
        "# Set up Notebook\n",
        "% matplotlib inline\n",
        "\n",
        "# Standard imports\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "from matplotlib import cm\n",
        "\n",
        "\n",
        "# We do this to ignore several specific Pandas warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "keVrDW_bUkj7"
      },
      "source": [
        " ## Read in the data cleaned out by R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zFRtuZDugFxL"
      },
      "source": [
        "If you are using google colab like me, you will need to mount your google drive first and  copy the cleaned dataset from the R project to your google drive. \n",
        "\n",
        "If you are using python/jupyter notebook locally, just point to the right directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL87zGxjfWxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mw_clust= pd.read_csv(\"data/clean/dataset/mw_dataset_cluster.csv\")\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/zhou100/FoodSecurityPrediction/master/data/clean/dataset/mw_dataset_cluster.csv'\n",
        "mw_clust = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amj_OZ_9t4BK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_tz = 'https://raw.githubusercontent.com/zhou100/FoodSecurityPrediction/master/data/clean/dataset/tz_dataset_cluster.csv'\n",
        "tz_clust = pd.read_csv(url_tz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5pltNNPuCn9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5aacd78-9cf4-45aa-9410-f6ead064ca39"
      },
      "source": [
        "url_ug = 'https://raw.githubusercontent.com/zhou100/FoodSecurityPrediction/master/data/clean/dataset/ug_dataset_cluster.csv'\n",
        "ug_clust = pd.read_csv(url_ug)\n",
        "ug_clust = ug_clust.replace([np.inf, -np.inf], np.nan)\n",
        "ug_clust = ug_clust.dropna()\n",
        "ug_clust.isnull().values.any()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sWyD9pyGg3tG"
      },
      "source": [
        "## Preprocessing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z4-7F9HoPcQq"
      },
      "source": [
        "### One-hot encoding for string variables "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o5G4izvkM1NP",
        "colab": {}
      },
      "source": [
        "mw_clust[\"FNID\"]= mw_clust[\"FNID\"].str.lstrip('MW2012C')\n",
        "fnid_mw_clust = pd.get_dummies(mw_clust[\"FNID\"],prefix='MW', drop_first=True)\n",
        "mw_clust = pd.concat([mw_clust, fnid_mw_clust], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NhZG9v9kZt4g",
        "outputId": "9289a35e-ee5d-4755-c48e-d8d87e62395e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "mw_clust.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FS_year</th>\n",
              "      <th>FNID</th>\n",
              "      <th>FCS</th>\n",
              "      <th>HDDS</th>\n",
              "      <th>rCSI</th>\n",
              "      <th>region_north</th>\n",
              "      <th>region_central</th>\n",
              "      <th>rural</th>\n",
              "      <th>dist_road</th>\n",
              "      <th>dist_admarc</th>\n",
              "      <th>dist_popcenter</th>\n",
              "      <th>percent_ag</th>\n",
              "      <th>nutri_severe_constraint</th>\n",
              "      <th>nutri_moderate_constraint</th>\n",
              "      <th>nutri_reten_severe_constraint</th>\n",
              "      <th>dummy_terrain_rough</th>\n",
              "      <th>FS_month</th>\n",
              "      <th>head_age</th>\n",
              "      <th>female_head</th>\n",
              "      <th>hhsize</th>\n",
              "      <th>floor_dirt_sand_dung</th>\n",
              "      <th>cell_phone</th>\n",
              "      <th>number_celphones</th>\n",
              "      <th>roof_not_natural</th>\n",
              "      <th>roof_iron</th>\n",
              "      <th>asset_index</th>\n",
              "      <th>clust_maize_price</th>\n",
              "      <th>clust_rice_price</th>\n",
              "      <th>clust_nuts_price</th>\n",
              "      <th>clust_beans_price</th>\n",
              "      <th>clust_maize_mktthin</th>\n",
              "      <th>clust_rice_mktthin</th>\n",
              "      <th>clust_nuts_mktthin</th>\n",
              "      <th>clust_beans_mktthin</th>\n",
              "      <th>lhz_maize_price</th>\n",
              "      <th>lhz_rice_price</th>\n",
              "      <th>lhz_nuts_price</th>\n",
              "      <th>lhz_beans_price</th>\n",
              "      <th>lhz_maize_mktthin</th>\n",
              "      <th>lhz_rice_mktthin</th>\n",
              "      <th>...</th>\n",
              "      <th>MW_3020213</th>\n",
              "      <th>MW_3020303</th>\n",
              "      <th>MW_3020403</th>\n",
              "      <th>MW_3020503</th>\n",
              "      <th>MW_3020513</th>\n",
              "      <th>MW_3020515</th>\n",
              "      <th>MW_3020603</th>\n",
              "      <th>MW_3020619</th>\n",
              "      <th>MW_3020703</th>\n",
              "      <th>MW_3020803</th>\n",
              "      <th>MW_3020813</th>\n",
              "      <th>MW_3020815</th>\n",
              "      <th>MW_3020913</th>\n",
              "      <th>MW_3030112</th>\n",
              "      <th>MW_3030114</th>\n",
              "      <th>MW_3030115</th>\n",
              "      <th>MW_3030204</th>\n",
              "      <th>MW_3030206</th>\n",
              "      <th>MW_3030214</th>\n",
              "      <th>MW_3030304</th>\n",
              "      <th>MW_3030306</th>\n",
              "      <th>MW_3030314</th>\n",
              "      <th>MW_3030404</th>\n",
              "      <th>MW_3030414</th>\n",
              "      <th>MW_3030506</th>\n",
              "      <th>MW_3030514</th>\n",
              "      <th>MW_3030519</th>\n",
              "      <th>MW_3030606</th>\n",
              "      <th>MW_3030613</th>\n",
              "      <th>MW_3030714</th>\n",
              "      <th>MW_3030716</th>\n",
              "      <th>MW_3030804</th>\n",
              "      <th>MW_3030816</th>\n",
              "      <th>MW_3030904</th>\n",
              "      <th>MW_3031005</th>\n",
              "      <th>MW_3031105</th>\n",
              "      <th>MW_3031206</th>\n",
              "      <th>MW_3031213</th>\n",
              "      <th>MW_3031313</th>\n",
              "      <th>MW_3999918</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>3010102</td>\n",
              "      <td>42.718750</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>2.750000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.656875</td>\n",
              "      <td>12.016250</td>\n",
              "      <td>62.406875</td>\n",
              "      <td>20.875000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>45.375000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>5.937500</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>-0.409163</td>\n",
              "      <td>44.282500</td>\n",
              "      <td>247.276000</td>\n",
              "      <td>235.426000</td>\n",
              "      <td>187.412000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.144094</td>\n",
              "      <td>194.816929</td>\n",
              "      <td>233.930246</td>\n",
              "      <td>167.089217</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013</td>\n",
              "      <td>3010102</td>\n",
              "      <td>41.500000</td>\n",
              "      <td>4.687500</td>\n",
              "      <td>11.625000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>12.687500</td>\n",
              "      <td>62.562500</td>\n",
              "      <td>23.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>47.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>6.187500</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>-0.587467</td>\n",
              "      <td>117.495000</td>\n",
              "      <td>338.092614</td>\n",
              "      <td>260.726301</td>\n",
              "      <td>169.705691</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.347005</td>\n",
              "      <td>390.687644</td>\n",
              "      <td>237.306038</td>\n",
              "      <td>271.791314</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010</td>\n",
              "      <td>3010102</td>\n",
              "      <td>35.218750</td>\n",
              "      <td>4.937500</td>\n",
              "      <td>2.687500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>10.821875</td>\n",
              "      <td>58.466875</td>\n",
              "      <td>48.687500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>43.187500</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>5.437500</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>-0.373761</td>\n",
              "      <td>31.591000</td>\n",
              "      <td>176.821000</td>\n",
              "      <td>180.817000</td>\n",
              "      <td>167.261000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.082676</td>\n",
              "      <td>141.357511</td>\n",
              "      <td>92.399333</td>\n",
              "      <td>144.797615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010</td>\n",
              "      <td>3010508</td>\n",
              "      <td>35.218750</td>\n",
              "      <td>4.937500</td>\n",
              "      <td>2.687500</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.513750</td>\n",
              "      <td>10.821875</td>\n",
              "      <td>58.466875</td>\n",
              "      <td>48.687500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>43.187500</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>5.437500</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>-0.373761</td>\n",
              "      <td>31.591000</td>\n",
              "      <td>176.821000</td>\n",
              "      <td>180.817000</td>\n",
              "      <td>167.261000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.082676</td>\n",
              "      <td>141.357511</td>\n",
              "      <td>92.399333</td>\n",
              "      <td>144.797615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013</td>\n",
              "      <td>3010102</td>\n",
              "      <td>48.088235</td>\n",
              "      <td>5.058824</td>\n",
              "      <td>2.411765</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>11.411765</td>\n",
              "      <td>56.529412</td>\n",
              "      <td>45.764706</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.058824</td>\n",
              "      <td>45.647059</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>5.529412</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>-0.322886</td>\n",
              "      <td>119.627402</td>\n",
              "      <td>400.969080</td>\n",
              "      <td>379.379586</td>\n",
              "      <td>347.946196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>96.706535</td>\n",
              "      <td>257.533827</td>\n",
              "      <td>244.449981</td>\n",
              "      <td>231.704856</td>\n",
              "      <td>0.627451</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 108 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   FS_year     FNID        FCS  ...  MW_3031213  MW_3031313  MW_3999918\n",
              "0     2010  3010102  42.718750  ...           0           0           0\n",
              "1     2013  3010102  41.500000  ...           0           0           0\n",
              "2     2010  3010102  35.218750  ...           0           0           0\n",
              "3     2010  3010508  35.218750  ...           0           0           0\n",
              "4     2013  3010102  48.088235  ...           0           0           0\n",
              "\n",
              "[5 rows x 108 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4HSNy0du4AC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "446dc315-56a9-428d-83d5-3481d0561797"
      },
      "source": [
        "tz_clust.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FS_year</th>\n",
              "      <th>FCS</th>\n",
              "      <th>HDDS</th>\n",
              "      <th>rCSI</th>\n",
              "      <th>rural</th>\n",
              "      <th>FS_month</th>\n",
              "      <th>region2</th>\n",
              "      <th>region3</th>\n",
              "      <th>region4</th>\n",
              "      <th>region5</th>\n",
              "      <th>region6</th>\n",
              "      <th>region7</th>\n",
              "      <th>region8</th>\n",
              "      <th>region9</th>\n",
              "      <th>region10</th>\n",
              "      <th>region11</th>\n",
              "      <th>region12</th>\n",
              "      <th>region13</th>\n",
              "      <th>region14</th>\n",
              "      <th>region15</th>\n",
              "      <th>region16</th>\n",
              "      <th>region17</th>\n",
              "      <th>region18</th>\n",
              "      <th>region19</th>\n",
              "      <th>region20</th>\n",
              "      <th>region21</th>\n",
              "      <th>region51</th>\n",
              "      <th>region52</th>\n",
              "      <th>region53</th>\n",
              "      <th>region54</th>\n",
              "      <th>region55</th>\n",
              "      <th>dist_road</th>\n",
              "      <th>dist_popcenter</th>\n",
              "      <th>percent_ag</th>\n",
              "      <th>nutri_severe_constraint</th>\n",
              "      <th>nutri_moderate_constraint</th>\n",
              "      <th>nutri_reten_severe_constraint</th>\n",
              "      <th>dummy_terrain_rough</th>\n",
              "      <th>head_age</th>\n",
              "      <th>female_head</th>\n",
              "      <th>asset_index</th>\n",
              "      <th>Cellphone</th>\n",
              "      <th>num_cell</th>\n",
              "      <th>floor_dirt_sand_dung</th>\n",
              "      <th>roof_not_natural</th>\n",
              "      <th>roof_iron</th>\n",
              "      <th>clust_maize_price</th>\n",
              "      <th>clust_rice_price</th>\n",
              "      <th>clust_bean_mktthin</th>\n",
              "      <th>clust_maize_mktthin</th>\n",
              "      <th>clust_rice_mktthin</th>\n",
              "      <th>lhz_maize_price</th>\n",
              "      <th>lhz_rice_price</th>\n",
              "      <th>lhz_bean_mktthin</th>\n",
              "      <th>lhz_maize_mktthin</th>\n",
              "      <th>lhz_rice_mktthin</th>\n",
              "      <th>raincytot</th>\n",
              "      <th>day1rain</th>\n",
              "      <th>maxdaysnorain</th>\n",
              "      <th>lhz_day1rain</th>\n",
              "      <th>gdd</th>\n",
              "      <th>tmean</th>\n",
              "      <th>lhz_raincytot</th>\n",
              "      <th>lhz_maxdaysnorain</th>\n",
              "      <th>heatdays</th>\n",
              "      <th>floodmax</th>\n",
              "      <th>lhz_floodmax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015</td>\n",
              "      <td>43.375000</td>\n",
              "      <td>5.250000</td>\n",
              "      <td>6.125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.464894</td>\n",
              "      <td>32.893617</td>\n",
              "      <td>32.898936</td>\n",
              "      <td>0.606383</td>\n",
              "      <td>0.313830</td>\n",
              "      <td>0.005319</td>\n",
              "      <td>0</td>\n",
              "      <td>41.375000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.765501</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>27708.0</td>\n",
              "      <td>175833.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44926.970174</td>\n",
              "      <td>175166.466099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>949.138410</td>\n",
              "      <td>5</td>\n",
              "      <td>148</td>\n",
              "      <td>81</td>\n",
              "      <td>213</td>\n",
              "      <td>27.410465</td>\n",
              "      <td>701.392269</td>\n",
              "      <td>142</td>\n",
              "      <td>213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015</td>\n",
              "      <td>33.562500</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>17.750</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.464894</td>\n",
              "      <td>32.893617</td>\n",
              "      <td>32.898936</td>\n",
              "      <td>0.606383</td>\n",
              "      <td>0.313830</td>\n",
              "      <td>0.005319</td>\n",
              "      <td>0</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>-0.886329</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21731.0</td>\n",
              "      <td>161538.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38137.865269</td>\n",
              "      <td>156000.969581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>948.396418</td>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "      <td>81</td>\n",
              "      <td>213</td>\n",
              "      <td>27.410465</td>\n",
              "      <td>701.392269</td>\n",
              "      <td>142</td>\n",
              "      <td>213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.142582</td>\n",
              "      <td>50.944231</td>\n",
              "      <td>23.662088</td>\n",
              "      <td>0.054945</td>\n",
              "      <td>0.708791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.583524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>34125.0</td>\n",
              "      <td>154166.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34493.312488</td>\n",
              "      <td>153017.457084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1008.294152</td>\n",
              "      <td>56</td>\n",
              "      <td>154</td>\n",
              "      <td>56</td>\n",
              "      <td>213</td>\n",
              "      <td>23.074113</td>\n",
              "      <td>1057.404969</td>\n",
              "      <td>122</td>\n",
              "      <td>213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015</td>\n",
              "      <td>40.642857</td>\n",
              "      <td>4.142857</td>\n",
              "      <td>2.000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.142582</td>\n",
              "      <td>50.944231</td>\n",
              "      <td>23.662088</td>\n",
              "      <td>0.054945</td>\n",
              "      <td>0.708791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>44.428571</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>-0.895485</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>1.285714</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>33000.0</td>\n",
              "      <td>172778.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33426.151812</td>\n",
              "      <td>171574.642544</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>946.519706</td>\n",
              "      <td>5</td>\n",
              "      <td>148</td>\n",
              "      <td>51</td>\n",
              "      <td>213</td>\n",
              "      <td>24.746366</td>\n",
              "      <td>779.541637</td>\n",
              "      <td>125</td>\n",
              "      <td>213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015</td>\n",
              "      <td>53.625000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.375</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.661765</td>\n",
              "      <td>70.922549</td>\n",
              "      <td>19.411765</td>\n",
              "      <td>0.009804</td>\n",
              "      <td>0.774510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>50.625000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.050865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>33000.0</td>\n",
              "      <td>172778.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33000.000000</td>\n",
              "      <td>172778.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>922.248186</td>\n",
              "      <td>5</td>\n",
              "      <td>117</td>\n",
              "      <td>50</td>\n",
              "      <td>213</td>\n",
              "      <td>24.762482</td>\n",
              "      <td>807.468836</td>\n",
              "      <td>123</td>\n",
              "      <td>213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FS_year        FCS      HDDS  ...  heatdays  floodmax  lhz_floodmax\n",
              "0     2015  43.375000  5.250000  ...       213       0.0           0.0\n",
              "1     2015  33.562500  4.500000  ...       213       0.0           0.0\n",
              "2     2014  34.000000  4.000000  ...       213       0.0           0.0\n",
              "3     2015  40.642857  4.142857  ...       213       0.0           0.0\n",
              "4     2015  53.625000  5.000000  ...       213       0.0           0.0\n",
              "\n",
              "[5 rows x 67 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhJste619U_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98432bf3-25f7-40f9-d1db-7776c7da8fb6"
      },
      "source": [
        "ug_clust['FCS_category']= pd.cut(x=ug_clust['FCS'], bins=[-1,28,42,200],labels= [2, 1, 0])\n",
        "ug_clust['HDDS_category']= pd.cut(x=ug_clust['HDDS'], bins=[-1,3,6,20],labels= [2, 1, 0])\n",
        "\n",
        "ug_clust.isnull().values.any()"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq_RKrrbu8fe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "991d3f3a-6dfa-4862-cd8a-43f09bed2f83"
      },
      "source": [
        "ug_clust.head()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FS_year</th>\n",
              "      <th>FNID</th>\n",
              "      <th>FCS</th>\n",
              "      <th>HDDS</th>\n",
              "      <th>rural</th>\n",
              "      <th>FS_month</th>\n",
              "      <th>region2</th>\n",
              "      <th>region3</th>\n",
              "      <th>region4</th>\n",
              "      <th>dist_road</th>\n",
              "      <th>dist_popcenter</th>\n",
              "      <th>percent_ag</th>\n",
              "      <th>nutri_severe_constraint</th>\n",
              "      <th>nutri_moderate_constraint</th>\n",
              "      <th>nutri_reten_severe_constraint</th>\n",
              "      <th>dummy_terrain_rough</th>\n",
              "      <th>head_age</th>\n",
              "      <th>female_head</th>\n",
              "      <th>asset_index</th>\n",
              "      <th>Cellphone</th>\n",
              "      <th>num_cell</th>\n",
              "      <th>floor_dirt_sand_dung</th>\n",
              "      <th>roof_not_natural</th>\n",
              "      <th>roof_iron</th>\n",
              "      <th>clust_cassava_price</th>\n",
              "      <th>clust_bean_mktthin</th>\n",
              "      <th>clust_maize_mktthin</th>\n",
              "      <th>clust_cassava_mktthin</th>\n",
              "      <th>lhz_cassava_price</th>\n",
              "      <th>lhz_bean_mktthin</th>\n",
              "      <th>lhz_maize_mktthin</th>\n",
              "      <th>lhz_cassava_mktthin</th>\n",
              "      <th>raincytot</th>\n",
              "      <th>day1rain</th>\n",
              "      <th>maxdaysnorain</th>\n",
              "      <th>lhz_day1rain</th>\n",
              "      <th>gdd</th>\n",
              "      <th>tmean</th>\n",
              "      <th>lhz_raincytot</th>\n",
              "      <th>lhz_maxdaysnorain</th>\n",
              "      <th>floodmax</th>\n",
              "      <th>lhz_floodmax</th>\n",
              "      <th>FCS_category</th>\n",
              "      <th>HDDS_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010</td>\n",
              "      <td>UG2011L141</td>\n",
              "      <td>47.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.81360</td>\n",
              "      <td>4.09120</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.933340</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>600.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>593.592838</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>474.492036</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>3</td>\n",
              "      <td>123</td>\n",
              "      <td>25.129216</td>\n",
              "      <td>558.706113</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011</td>\n",
              "      <td>UG2011L141</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.43450</td>\n",
              "      <td>65.52810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.270643</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>702.971126</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.028336</td>\n",
              "      <td>1823.754595</td>\n",
              "      <td>3</td>\n",
              "      <td>143</td>\n",
              "      <td>3</td>\n",
              "      <td>488</td>\n",
              "      <td>23.691104</td>\n",
              "      <td>1866.829980</td>\n",
              "      <td>18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012</td>\n",
              "      <td>UG2011L137</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.63892</td>\n",
              "      <td>48.91718</td>\n",
              "      <td>19.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>36.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.033716</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1193.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1197.521782</td>\n",
              "      <td>0.01498</td>\n",
              "      <td>0.01498</td>\n",
              "      <td>0.014980</td>\n",
              "      <td>2040.792751</td>\n",
              "      <td>17</td>\n",
              "      <td>40</td>\n",
              "      <td>14</td>\n",
              "      <td>489</td>\n",
              "      <td>23.937279</td>\n",
              "      <td>1939.734309</td>\n",
              "      <td>24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012</td>\n",
              "      <td>UG2011L140</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.63892</td>\n",
              "      <td>48.91718</td>\n",
              "      <td>19.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>36.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.033716</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1193.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1197.521782</td>\n",
              "      <td>0.01498</td>\n",
              "      <td>0.01498</td>\n",
              "      <td>0.014980</td>\n",
              "      <td>2040.792751</td>\n",
              "      <td>17</td>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "      <td>489</td>\n",
              "      <td>23.030044</td>\n",
              "      <td>1967.415063</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012</td>\n",
              "      <td>UG2011L141</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.63892</td>\n",
              "      <td>48.91718</td>\n",
              "      <td>19.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "      <td>36.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>-0.033716</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1193.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1197.521782</td>\n",
              "      <td>0.01498</td>\n",
              "      <td>0.01498</td>\n",
              "      <td>0.014980</td>\n",
              "      <td>2040.792751</td>\n",
              "      <td>17</td>\n",
              "      <td>40</td>\n",
              "      <td>5</td>\n",
              "      <td>489</td>\n",
              "      <td>23.658749</td>\n",
              "      <td>2223.933356</td>\n",
              "      <td>13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FS_year        FNID   FCS  ...  lhz_floodmax  FCS_category  HDDS_category\n",
              "0     2010  UG2011L141  47.5  ...           0.0             0              2\n",
              "1     2011  UG2011L141  20.0  ...           0.0             2              2\n",
              "2     2012  UG2011L137  52.0  ...           0.0             0              1\n",
              "3     2012  UG2011L140  52.0  ...           0.0             0              1\n",
              "4     2012  UG2011L141  52.0  ...           0.0             0              1\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnL-llJixXJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ug_clust = ug_clust.drop(\"FNID\",axis =1 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_cqm_RO7LXk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78886ecb-9d52-440f-add2-7e6fbbd778c8"
      },
      "source": [
        "ug_clust.isnull().values.any()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EHTKzlm8G7rS"
      },
      "source": [
        "# Methodology\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G1SERn3aHD_P"
      },
      "source": [
        "This section will explain our main approach with the data.\n",
        "\n",
        "1. Focus on categorical prediciton for the given cutoffs. \n",
        "\n",
        "Reasons: Close to the actual policy scenarios where we focus on capturing all the insecure households. Recall rate of the insecure villages is more important than the over all accuracy. \n",
        "\n",
        "Can apply the down sampling and over sampling technique here to improve \n",
        "\n",
        "\n",
        "2.  Algorithms to try : tree classifier, random forest classifier, xgboost \n",
        "\n",
        "2.1. By categories, vs one or rest\n",
        "\n",
        "2.2.  Parameter Tuning\n",
        "\n",
        "2.3 . feature importance analysis\n",
        "\n",
        "\n",
        "3.  Error analysis by region, by group, by month\n",
        "\n",
        "4.  Train model by division separtely Auto-segmentation by training a shallow tree in each country based on observables \n",
        "\n",
        "5. Model combination: what happens when we train on all the data \n",
        "\n",
        "6. Model generalization issues: what happens when we directly apply  models trained on one country to predict another \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DSo3Zuh0jAN8"
      },
      "source": [
        "## Exploratory Data Analysis  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0EVf0OgQhyzj"
      },
      "source": [
        "### Measures:  plot target measures by year by country\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vQVpjOMObguF",
        "outputId": "cfbc2b15-189b-4028-a4e2-9cb33a1b1aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# cut the outcome variables by the cutoffs\n",
        "mw_clust['FCS_category']= pd.cut(x=mw_clust['FCS'], bins=[-1,28,42,100],labels= [2, 1, 0])\n",
        "  \n",
        "mw_clust['FCS_category'].value_counts().plot(kind='pie', title=' Counts (FCS categories)')\n",
        "\n",
        "\n",
        " # HDDS 3 and 6\n",
        "mw_clust['HDDS_category']= pd.cut(x=mw_clust['HDDS'], bins=[0,3,6,10],labels= [2, 1, 0])\n",
        "  \n",
        "mw_clust['HDDS_category'].value_counts().plot(kind='pie', title='Count (HDDS categories)')\n",
        "\n",
        "# rCSI 4 and 17  and 42\n",
        "mw_clust['rCSI_category']= pd.cut(x=mw_clust['rCSI'], bins=[-1,4,17,42],labels= [0, 1, 2])\n",
        "  \n",
        "mw_clust['rCSI_category'].value_counts().plot(kind='pie', title='Count (rCSI categories)')\n",
        "\n",
        "\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63b080940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mEIDc34pb6jK",
        "outputId": "f0d34dd1-9375-4b77-9924-01acb052ffdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# cut the outcome variables by the cutoffs\n",
        "tz_clust['FCS_category']= pd.cut(x=tz_clust['FCS'], bins=[-1,28,42,200],labels= [2, 1, 0])\n",
        "\n",
        "tz_clust['FCS_category'].value_counts().plot(kind='pie', title=' Counts (FCS categories)')\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63b1a2278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuqDVxU4yy3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "8c4a48c9-71ed-48ce-9742-10a404c4e9f2"
      },
      "source": [
        "# HDDS 3 and 6\n",
        "tz_clust['HDDS_category']= pd.cut(x=tz_clust['HDDS'], bins=[-1,3,6,20],labels= [2, 1, 0])\n",
        "\n",
        "tz_clust['HDDS_category'].value_counts().plot(kind='pie', title='Count (HDDS categories)')\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63b180240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcW3W9//HX58x0pi1doOxCa4CC\n7ItQFhEEEQEDYhFERIsoKl5AFOF6Lm6Dika8F6FXVED9qWUpSEHRFEGWCgJSKIsFkUVNoVDW0nSW\nznQy8/n98T3DjeMsJzNJvknO5/l45NGZk5Oc96T5nO9Zv19RVYwxjS3wHcAYU3lW6MYkgBW6MQlg\nhW5MAlihG5MAVujGJIAVumcisqmI/E1EJvnO0qhE5AkROWSc77FIRI4qU6SqS0Shi8hHROQhEekQ\nkVUicouIvLMKy1URmT3KbCHwc1VdF71miYicNuh9DhGRlUW/LxGRbhFpF5G1IrJMREIRaS2ap01E\neqN52kXkaRH5gYhsOei9zxeRf0afzUoRuW78f/m/EpGciLyn3O8bl6ruoqpLxvk23wW+VYY4XjR8\noYvIOcAlwLeBzYFZwA+BY33mAogK8xTgqjG8/ExVnQpsCXwR+DCwWESkaJ7ronlmAHOBLYBlA8Uu\nIqcAHwPeo6pTgH2AO8b699QaEWku13up6lJgmojsU673rKaGLnQRmQ58AzhDVW9U1U5V7VXV36rq\nedE8rSJyiYi8GD0uGWgZReTjIvKnQe/5ZistIj8XkctEJBu1mg+IyHbRc3dHL3ksai1PHCLifsAa\nVV05xHOxRH/TEuD9wAFAeoh5elX1CeBE4FXcigFgDnCrqv49mu8lVb1iuGWJyEwRuVFEXhWR10Xk\nB9H07UTkzmjaayJytYhsGD23ALdy/W30OfxnNH1/EblPRNaIyGPFm9Yiso2I3B19prdHn/FVRc+/\nP9ocXxNt3exU9FxORL4kIn8BOkWkuXiLQkSCaOvn71He60VkRvTcRBG5Kpq+RkQeFJHNiz6CJUN9\nvvWgoQsd98WfCNw0wjxfBvYH9gT2APYFvlLCMj4MXABsBDwLXAigqgdHz++hqlNUdahN4t2Ap0pY\n1rBU9TngIeCgEebpA35TNM+fgXkicp6I7CMiTcO9Nnrud8AKIAVsBSwceBr4DvAWYCdgJtAWLfNj\nwHPAMdHncJGIbAVkcZvCM4BzgUUismn0ftcAS4GNo/f5WFGOHYBrgc8DmwKLcSuRlqK4J+EKckNV\nLQz6U84CPgC8K8r7BnBZ9NwpwPQo/8bA6cC6otc+ifuO1J1GL/SNgdeG+M8udjLwDVV9RVVfxRXt\nx0aYf7CbVHVptIyrcSuMuDYE2oeYPj9qUdaIyBpcgcXxIq5wYs2jqlfhvvhHAH8EXhGRLw3zun1x\nhXFetBXRrap/it7nWVX9g6r2RJ/hxbhCGs5HgcWqulhV+1X1D7iV1PtEZBZuS+Nrqro+WsbNRa89\nEchGy+sF/huYBLyjaJ75qvr8wHGPQU4HvqyqK1W1B7ciOT7azO/FfWdmq2qfqi5T1bVFr23H/Z/V\nnUYv9NeBTUbZV3sLrpUasCKaFtdLRT93AVNKeO0bwNQhpn9OVTcceABHx3y/rYDVpcyjqler6ntw\nX+DTgW+KyBFDvG4msGKolaaIbC4iC0XkBRFZizvmsMkIGd4KnDBoZfZO3PGGtwCrVbWraP7ni37+\nl/8vVe2Pnt9qmPmHWvZNRct9EujDHb9ZANwKLIx24y4SkQlFr50KrBnhvWtWoxf6/UAPblNtOC/i\n/vMHzIqmAXQCkweeEJEtypzvL8AO5XgjEZkJ7A3cM8I8AXDMUPNE+/G/ijLtOsTLnwdmDbPS/Dag\nwG6qOg3XYhcfFBx8i+TzwILilZmqbqCqGWAVMENEJhfNP7Po53/5/4oOPs4EXhhheYOXfdSgZU9U\n1Reiz+ACVd0Zt4VwNDCv6LU7AY+N8N41q6ELXVXzwNeAy0TkAyIyWUQmiMhRInJRNNu1wFfEnc/e\nJJp/4MDPY8AuIrKniEwk2u8swcvAtiM8vxTYMNpnHZPob3oXbt97KW6fdfA8zdEBq2txR94vjqZ/\nXETSIjI1Okh1FLAL8MAwWVcBGRHZIDpwdWD03FSgA8hHf8t5g147+HO4CjhGRI4QkabovQ4Rka1V\ndQVuM75NRFpE5ADcymnA9UBaRA6LWtsv4lbm98X8yH4MXCgib40+g01F5Njo50NFZLfoeMRa3KZ8\nf9Fr3wXcEnM5tUVVG/6B2w9/CNdCv4Q7EPSO6LmJwHzcl3hV9PPEotd+GXgN1xJ8FNdazI6e+znw\nraJ5DwFWFv1+evSea4APDZPte8CXin5fApw2aJ7B77sE6MbtM7YDj0Q5i3O34b6oHdHf/QzutOJW\nRfMcB9yL24VYCywHPj7C5zgL+DVul+g13L4wuJXDsmhZj+KKrzjvsbgDcmuAc6Np++GOC6zGnQnI\nArOi57bDbXW04073XQH8tOj95gJ/BfLRe+xS9FwOd7qQoabhGrdzcAdB24G/A9+Onjspmt6JWznN\nB5qj5+YAD/v+Lo/1IdEfYTyJjjTfA+ylQx88SjxxF/H8TVW/7jHDItzK5t+2mOqBFbqpOSIyB9fS\n/xN4L24r4gBVfcRrsDpWtiuHjCmjLYAbcae6VgKftSIfH2vRjUmAhj7qboxxrNCNSQArdGMSwArd\nmASwQjcmAazQjUkAK3RjEsAK3ZgEsEI3JgGs0I1JACt0YxLACt2YBLBCNyYBrNCNSQArdGMSwArd\nmASwQjcmAazQjUkAK3RjEsAK3ZgEsEI3JgGs0I1JACt0YxLABnBIkFSY3QA3PPDmuGGNJwEtwASg\nCTeunAIF3Lhmq4ser+cy6fUeYpsysAEcGkgqzDbjhmHeJXrsjBtSeKC4Jw//6li6cIMPPgM8HT2e\niv59LpdJ94/wWuORFXqdSoXZANgLN5TvvrjC3gHXQvvQDTyOG531T8C9uUx6lacsZhAr9DoRFfae\nuCGUDwEOAjb0GCmOf+KK/k/ArblMeoXnPIllhV7DUmF2EnAEbhzzNDDDb6JxWw7cDNyUy6SX+Q6T\nJFboNSYVZicARwIfAY4BNvCbqGL+AdwAXJvLpB/1HabRWaHXiFSY3QE4AzgZN1xwkjwI/BhYmMuk\nu3yHaURW6B6lwqwARwFn4TbRxW8i79YAC4DLc5n0E77DNBIrdA9SYXYacCquBd/ec5xadTfwnVwm\n/XvfQRqBFXoVRResfAE4F5juOU69uB+4IJdJ3+o7SD2zQq+CVJhtBU4Hzgc28xynXt2HK/jbfAep\nR1boFZQKs03AKcDXgVme4zSKe4Fzcpn0Ut9B6okVeoWkwuzBuCPJO/nO0oD6gZ8A/5XLpFf7DlMP\nrNDLLBVmNwL+G3ewLelH0SvtNSAEfpbLpO2LPAIr9DJKhdmPAN/H9sOr7c/Af+Qy6Ud8B6lVVuhl\nkAqzKdxm+hGeoyRZAfg28M1cJl3wHabWWKGPU9SK/xiY6juLAdxVdh/NZdJP+w5SS6zQxygVZqcA\nlwHzfGcx/6YTODOXSf/cd5BaYYU+BqkwuzOwCNjRdxYzogW4ffcO30F8s0IvUSrMngxcTuPeVdZo\nHgeOTvq98FboMUU3oFwI/JfvLKZkLwMfyGXSf/YdxBcr9BhSYbYF+BnuFlJTn7qBU3OZ9ELfQXyw\n7p5HkQqzGwK3YkVe7yYC16TC7Nd8B/HBWvQRpMLsLGAxruNF0zh+CXwil0n3+Q5SLVbow0iF2V2A\n24C3+M5iKmIh7nx7IordCn0IqTD7NuCPuL7QTeO6Hjg5CVfSWaEPkgqz2+F6N7GWPBluAE5q9GK3\ng3FFUmH2rcCdWJEnyfHAdVHvuw2rrgtdRH4mIq+IyOPjfa9UmN0auAvrICKJjgMWRNdKNKS6LnTg\n57g+0MclFWY3Bu4Athnve5m6dSLu7reGVNeFrqp340b6HLNok20Rbtwyk2xhKsye5jtEJdR1oZfJ\nZbiBCo0B+FEqzB7uO0S5JbrQU2H2c8CnfOcwNaUZuCG6jqJhJLbQU2H2vcDFvnOYmjQNWJwKs5v4\nDlIuiSz0aJyz64Am31lMzZpFAx2Jr+tCF5FrcSN5vE1EVorIJ0d7TTSYwnXU/tjixr8jcb3M1r3E\nXRmXCrOXAGf7zmHqRh/wrlwmfa/vIOORqEJPhdkjgVt85zB1Jwfskcuk1/oOMlZ1veleilSYnYHr\nPMKYUqWAH/oOMR6JKXTcf9SWvkOYunVyKsy+33eIsUrEpnsqzM4FbvSdw9S954Cdc5l0p+8gpWr4\nFj0VZicBl/jOYRrCLNzIuHWn4Qsd12ur3ZFmyuULqTC7q+8QpWroTfdUmN0WeALXMaAx5XIvcFA9\njeDa6C36JViRm/I7EPiE7xClaNgWPRVmj8L14GpMJbwEbJvLpNf5DhJHQ7boqTAbAP/jO4dpaFsA\n/+E7RFwNWejACcBOvkOYhvelaFTdmtdwhR7dbfQV3zlMImwKfM53iDgartCBuUDdnf4wdevcVJid\n7jvEaBqx0L/qO4BJlI2Ac3yHGE3sQheRZSJyhohsVMlA45EKs8cAe/rOYRLnzOgKzJpVSot+Im5g\ngwdFZKGIHCEitdb7ho1dbnyYAXzYd4iRxC50VX1WVb+M6xb5GtwtnytE5AIRmVGpgHGlwuzuwAG+\nc5jEOsN3gJGUtI8uIrvjzk9/D9cX+gnAWtwwRr5Zb67Gp71TYXY/3yGG0xx3RhFZBqwBfgqEqtoT\nPfWAiBxYiXBxRftHH/WZwRhcq/6A7xBDidWii0gALFLVw1T1mqIiB0BVj6tIuviOxzp7NP59qFa7\niI5V6KrajxuIrlZ92ncAY4BWYJ7vEEMpZR/9dhE5V0RmisiMgUfFksWUCrM7Au/0ncOYyEm+Awyl\n1NNrZwB3A8uix0OVCFWimj6tYRJnn1SY3c53iMFiH4xT1VodUriWdylMMn0I+I7vEMVKuTJugoh8\nTkRuiB5nisiESoYbTSrMzgZ285nBmCHM9R1gsFI23X8E7I3rNvmH0c8/qkSoEhzrefnGDGWfVJjd\n2neIYrE33YE5qrpH0e93ishj5Q5UorTn5RszFAHeTw0N+lBKi94nIm8eZBCRbXHjUnmRCrPTsKPt\npna9x3eAYqW06OcBd4nIP3BrrLcCp1YkVTyHAV6PERgzgoN8ByhWyk0tdwDb43rUOAt4m6reValg\nMbzD47KNGc0mqTC7s+8QA0q51n3waazZIpIHlqvqK+WNFYvdqWZq3UHAX32HgNI23T+JK66BVvwQ\n3EUz24jIN1R1QZmzDSsVZifgjvobU8sOBi73HQJKK/RmYCdVfRlARDYHfgnsh7tarmqFjutFxgZm\nMLXuYN8BBpRy1H3mQJFHXommrQZ6yxtrVLbZburB1qkwWxPj/pXSoi8Rkd8Bv4p+Pz6atgHuPvVq\nskI39WIX3HDLXpVS6GfgrisfOHf9C9w96gocWu5go9hj9FmMqQk7Abf4DlHKTS0qIg8BeVW9XUQm\nA1OA9oqlG0I03NK21VymMeNQEyMGlXJTy6eAG/i/o4hbAb+uRKhRzMTd4G9MPaivQsdtuh+I6wwS\nVX0G2KwSoUYx28MyjRmruiv0HlVdP/CLiDQDPsZctkI39WRGKsz6aBD/RSmF/kcROR+YJCKH446+\n/7YysUZkhW7qjffvbCmFHgKvAsuBzwCLowEdqq3muukxZhSb+g5Qyum1s1T1UuDKgQkicnY0rZq2\nqPLyjBkv711Al9KinzLEtI+XKUcprP92U2+8F/qoLbqInAR8BHfzys1FT00FVlcq2AhqfixqYwap\ni033+4BVuLXS/xRNbwf+UolQo7AW3dSb2m/RVXUFsIIauL48FWabgcm+cxhTIu+FXsqVcfuLyIMi\n0iEi60WkT0TWVjLcEKw1N/Vomu8ApRyM+wFuuJlngEnAacBllQg1Au8fmDFj0BRnpmi4s7tE5K8i\n8oSInF2uACWNj66qzwJNqtqnqv8POLJcQWIq5XSgMbUi7ve2AHxRVXcG9gfOEJGy9DtXSuF0iUgL\n8KiIXIQ7QFfSiqIMfFxymwiT6On67IRFS/PS3J8PmlgbNGt7ENARCJ2B0BUg6wKkJ9BAXS/AJibV\n5ufiDEGgqqtwdYWqtovIk7ibx8bd71wphf4xXGGfCXwBdxfZB8cboERW6BWyjtbJnwl+P6tVCu4W\n4P7oMYQeobtLgq7OQNZ1BEFPpwQ9HYGsbw+C3rVB0NveFPS1B0F/9KBTRDqDQLoCCdaJNPe4x4Re\nkdY+kZY+mNgPkxQmI9KIdyYuK/UFIpIC9gIeKEeAUgr9NWC9qnYDF4hIE9W/XbRQ5eUlyu/7933u\n2Kb7Rr3Xv1WZ2Kr9Ezfqh3KP4dEHfV0inV1BsK4zkO6OIOhuD4L17iGF9iAoDKxEOoJAOwKhUwLp\nDIJgnUhTd+BWIutFWgrQ0icysQ8mqjtbMxkRH1sjJXW1JiJTgEXA51W1LAe8Syn0O3CjT3REv08C\nbqO6/av3VHFZifP9wge3O7bpPq8ZmqBpquq0qX1908o9DpCCdot0dYms6wqCdR2B9HQEQU+0Iul1\nKxHpWxsEfR1BoO1BQGcQSKeIdAXS1C1Bc49I03qhpVekpSDSGm2NDKxEhhtQJPb3Nhq4dBFwtare\nWI6/G0or9ImqOlDkqGpH1MtMNXVXeXmJktMtZ+Z18vLp0tWQI9QKyCTVyZNUJ2/cP8x+yTj0Qm9X\nIF1utybo7gikpz0I1neLPB0rn9va+CnwpKpeXM5spRR6p4i8XVUfjkLtDawrZ5gYuqq8vMS5ru/Q\nNz7dnPUdoy5NgAnT+3X6dPqm0/cvmyNxD6YdiDsWtlxEHo2mna+qi8ebTVzfjjFmFJkDLARexB11\n3QI4UVVLPtAwHqkwm8fOp1fMRqxd/XDr6VNFbFy7MrqCtvxnfAYopXPIB0VkR+Bt0aSnVPXNgwwi\ncriq/qHcAYewCiv0inmDaTNeZOOlW/H6vr6zNJBqd4f+b0q9YKZXVR+PHoOPJH63jLlGsqpKy0ms\nnxbe52047Aa10neAcl7wUq3TFlboFXZN37v3VK1uN94NzvsADuUs9GpdzGKFXmHdtE56Umf5uAW5\nUTVUoVeLFXoV/KAwd5LvDA2koQo9V8b3GsnzVVpOot3SP2fPPpWXR5/TjKKTtvzrvkOMWugiMkdE\ntij6fZ6I/EZE5ovIjIHpqnpcpUIO8kSVlpNoShDc17/L33znaADeW3OI16JfDqwHEJGDgQxuXPQ8\ncEXlog3rqYE8prK+Xzh+c98ZGsCTvgNAvEJvisZABzgRuEJVF6nqV/HQMX0uk+4FrKWpgod1hx27\ndcLffeeoc4/4DgAxCz0afgngMODOoud8dQRhR4SrZHH/fnZMZHwe9h0A4hX6tbjhmH6Du7b9HgAR\nmY3bfPdhuaflJs6lheNmq1o/AONQEy16nF5gLxSRO4Atgdv0/y6OD4CzKhluBNaiV8kK3WLrPBv8\nZUM6d/edpQ69RFu+Jk4Hxzq9pqp/Bp4F3iciJ4jIrqr69MCdbB48hPU2UzXX9r3b15ZbvauJ1hzi\nnV6bLiJLgF/jRmw5GfhN1Full5tLcpn0a9jme9VcXjh6V1U70zEGZekGqhzitOjfxLWg26vqXFX9\nALA98CBwYSXDjeIOj8tOlDVM3egFNqmZ1qmOVONuzljiFPp7gFBV3+ySI/r5/Og5X6zQq+jKQtp2\nlUqTB5b6DjEgTqGvV9V/65QxmuazD7e7sc4iq2Zh36F7qlLtkXnq2V205Wvm+xmn0CeKyF4i8vZB\nj72pfi+wb8pl0u243QdTBT20TPyrvtXOdsRXM5vtEO+Cl1XAcB3VvVTGLGNxOzUw+GNSzC/M3eDy\nlkt8x6gXt/kOUCzOefRDqxFkjG4Gvuo7RFLc1r/PHn0arGqS/i19Z6lxf6ct/6zvEMVinUcXkY1F\n5CwRuSx6nFl855ovuUz6IeCfvnMkhRIE9/bvEqvr4oRb6DvAYHHOo+8EPA7sDTyNG011DvB41Fmk\nbzf4DpAk3y8cb6356K72HWCwOPvo3wTOVtXriyeKyAdx59GrPf7aYAuB8zxnSIxHdPsdunXCMxOl\nd3vfWWrUo7Tla+LW1GJxNt13G1zkAKq6CNi1/JFKk8ukH6YMo02a+H7Xf8ALvjPUsGt8BxhKnELv\nHONz1XSV7wBJcmnhuO3tjrYhKe5uz5oTZ9N9MxE5Z4jpAmxa5jxjtQD4Bv7uj0+U53WzrdYw5bGN\n6NjDd5Yas4S2vPc+3IcSp0W/Epg6xGMK8JPKRYsvl0mvBMo28qQZ3TV9h9lVcv9uvu8Aw4k99lqt\nS4XZAwC/Y/4myHQ61jza+unJIrT4zlIj/gFsT1u+/MO0lsGohS4iI66lVPVzZU00Dqkw+2dgP985\nkuKelrMfmBm8ap+38wXa8jV72WCcTfdlRY/3D/q9qiOpxnCp7wBJckXf0Y2xOTh+7cDPfIcYSUmb\n7iLyiKruVcE845IKs824K+W29p0lCVro7Xmq9ZRuEab7zuLZpbTlP+87xEhKHamlptfguUy6APyv\n7xxJsZ4JrY/rNknv6aeXOtiSrMex10bzA/zfVZcY8wtzp/jO4NlPaMvX/P0Wca51bxeRtSKyFth9\n4OeB6VXIWJJcJt2FO6duquAP/XvvUdDgRd85POnCXSJe80YtdFWdqqrTokdz0c9TVdVL55AxXIm7\n+cZUnMg9/bsl9Y62+bXSnfNoGnHTfWBf/Su+cyTFJYXjt/KdwYM1wEW+Q8TVkIUe+RWu91pTYY/p\ndtuv05akbUF9l7b8G75DxNWwhZ7LpBX4ku8cSXFzX6LuaPsHdXCkvVjDFjpALpO+kxrsBKARzS8c\n97YE3dF2Om35db5DlKKhCz3yeeA13yEa3QtsuuUbTH3Md44quJq2fE318BpHwxd6NHxTTV+11Ciu\n6jusw3eGClsNfMF3iLFo+EIHyGXSVwOLfedodFcW0rupeh3Uo9L+k7b8q75DjEUiCj3yWaDRWxyv\n2tlg+nO6WaOO0XYXNX7jykgSU+i5TPo54D9952h0l/cdLb4zVMAbwDza8nV7sLFhOp6IKxVmbwTm\n+s7RqCZQWP9U67yuQNjQd5YyOp62/CLfIcYjMS16kU8CK3yHaFS9NLcs120b6Y62K+q9yCGBhZ7L\npN8ATgTW+87SqC4tHFer90CU6lHg7NFmEpEjReQpEXlWRMIq5CpZ4godIJdJP0CdniapB3f277V7\nQYN6v1IuD5xAW757pJlEpAm4DDgK2Bk4SUR2rkK+kiSy0AFymfQPgV/6ztGYRP7Yv0c9X/tewO2X\nxxkocV/gWVX9h6qux40cdGxF041BYgs98hngHt8hGtHFhePruTuvz9KWvz3mvFsBzxf9vjKaVlMS\nXei5TLob1+HlE76zNJondJvZXdpSj/epX0RbvibGKyinRBc6QC6TXgMciVsTmzL6Td+BddEpQ5Eb\ngFIPpr0AzCz6fetoWk1JfKHDmyO9HInrTMCUyf8W5u6gSk0OaDCE+xnbRTEPAtuLyDYi0gJ8GLi5\n7OnGyQo9ksukn8AdRGnka7Wr6kU22XJ1fdzRthQ4aiy3nqpqATgTuBV4ErheVWtuV9AKvUguk74b\nd9XciKdUTHwL+g6vlRF3h7MUeC9t+fxY30BVF6vqDqq6napeWMZsZZO4S2DjSIXZQ3GbX0nvynjc\nptC1dnnraS0iTPSdZQgPAoePp8jrhbXoQ8hl0ncB78X22cetg8nTVujmj/rOMYSHGGdLXk+s0IeR\ny6TvB96N9U4zbj/qO6bWvmdLcC15Ylbktuk+ilSY3Qm4HXiL7yz1qplC79Ot8zoCYSPfWYAFwGm0\n5RN1r0OtrWlrTi6TfhKYgztoY8agQPOEx3T2475zABfQlp+XtCIHK/RYcpn0i8C7cK2BGYNLC8f5\nHHG1FziFtnybxwxe2aZ7iVJh9hzcCB1NvrPUF9VnWue9MEH6qn0N/MvAh2nLL6nycmuKteglymXS\nFwPvw47Il0hkSf8ece4GK6c7gD2TXuRghT4muUz6NmBv4AHfWerJxYUTZo4+V1n0AV/DnT6zIbSx\nTfdxSYXZZtwX6nxsUz6WJ1pP/dsG0rNjBRfxIvAR2vJ/rOAy6o616OOQy6QLuUz6a8BBQD3ekll1\nN/W98+UKvv1C3Ka6Ffkg1qKXSSrMTgIuxPUxZivQYWzB6pfvbz1zU5GyfkYrcJ1F3FLG92woVuhl\nlgqzc4D5wP6+s9Sqh1pPf3gTWfv2MrxVH+6z/ipt+Vq/ecYra3nKLJdJPwi8A5iH2180g/yi8N5y\njES6DNiftvw5VuSjsxa9glJhdgruQN05QKvnODVjA9a1P976yWYRJo3h5c8CXwGur+eRU6rNCr0K\nUmF2W+BbwIewo/MA3Nlyzv3bBi8dUMJLXgK+AfyEtnxvhWI1LCv0KkqF2dm4PsnmARM8x/HqhKYl\nD35vwhVzYsz6BnAx8H3bRB87K3QPUmF2JnAu8CkY0+Zr3XN3tJ3SHojOGGaWZ4BLgF9YgY+fFbpH\nqTC7KXAWcCqu99BEWdTy9bv3Dp45eNDkJbgW/He2D14+Vug1IBVmA+AI4BO4fuZb/CaqjoOCvyxf\n0JLZDbd5vhC4krZ8o46v7pUVeo1JhdlNgI/iRn3d1XOcSuoBFv+19dQFk6VnMW156323gqzQa1gq\nzO6I64L6A8B+gPhNNG5rgbuAm4Cbcpn0Ws95EsMKvU5E+/NH4AaaOBzYzG+iWAq4nnn+ANwGLM1l\n0gW/kZLJCr1ORefm940e+wF74f8I/ircmOKP4m7hvcta7dpghd4goltmdwN2B7aNHttE/25B+Tb7\ne3Bji60EngOWExV3LpN+pUzLMGVmhZ4A0Z11Kdzm/tToMa3o56m4+x4K0WM90AV0Ro+XiIo7l0m/\nXuX4pgys0I1JALt7zZgEsEI3JgGs0I1JACt0YxLACt2YBLBCNyYBrNCNSQArdGMSwArdmASwQjcm\nAazQjUkAK3RjEsAK3ZgEsEI3JgGs0I1JACt0YxLACt2YBLBCNyYBrNCNSQArdGMSwArdmASwQjcm\nAazQjUkAK3RjEsAK3ZgEsEJcS8tcAAAAIUlEQVQ3JgGs0I1JACt0YxLACt2YBLBCNyYBrNCNSYD/\nDwmThzr5Zzx5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQVa2nvKyxVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "c55f181a-f0b6-461d-a6b9-07534337ce7e"
      },
      "source": [
        "# rCSI 4 and 17  and 42\n",
        "tz_clust['rCSI_category']= pd.cut(x=tz_clust['rCSI'], bins=[-1,4,17,43],labels= [0, 1, 2])\n",
        "\n",
        "tz_clust['rCSI_category'].value_counts().plot(kind='pie', title='Count (rCSI categories)')\n"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63b12eeb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5IAcP+CEe78AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiRa0o7NcZ5N",
        "outputId": "e28a848b-7c2c-4ab3-d334-43a80cd2c0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# cut the outcome variables by the cutoffs\n",
        "ug_clust['FCS_category']= pd.cut(x=ug_clust['FCS'], bins=[-1,28,42,200],labels= [2, 1, 0])\n",
        "\n",
        "ug_clust['FCS_category'].value_counts().plot(kind='pie', title=' Counts (FCS categories)')\n",
        "\n",
        "\n"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63b0e7d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwjrBOeNy4XB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "f759cb17-ff8e-4125-e7dc-0eed293b2872"
      },
      "source": [
        "# HDDS 3 and 6\n",
        "ug_clust['HDDS_category']= pd.cut(x=ug_clust['HDDS'], bins=[-1,3,6,20],labels= [2, 1, 0])\n",
        "\n",
        "ug_clust['HDDS_category'].value_counts().plot(kind='pie', title='Count (HDDS categories)')\n",
        "\n",
        " "
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb63b11fcc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XeYXGXZx/HvPTMb0oAQAgmEhIGE\nZiDUYIBIgoAIAyJIEZXy2kApIoIeASX4WkYQDUjRSBUFRCMgHhBpoSolFEOH4ACBFBKS3U3ber9/\nPGd12HfLzO7MPjNz7s91zXXtnnPmnN/Ozn2e0x9RVYwxtS3hO4Axpvys0I2JASt0Y2LACt2YGLBC\nNyYGrNCNiQErdM9EZBMReUVEhvjOUqtE5EURmdHPecwRkYNLFGnAxaLQReRzIvK0iKwSkUUicreI\nTBuA5aqITOxlsgC4XlXXRu+ZKyJf7jSfGSKyMO/3uSKyTkQaRaRBROaJSCAi6+VNM1NEWqJpGkXk\nNRG5XEQ26zTvc0Xk39Fns1BE/tD/v/zDRCQnIgeUer6FUtVJqjq3n7P5KfDDEsTxouYLXUTOAmYB\nPwZGA+OBK4HDfeYCiArzROB3fXj7aaq6PrAZ8C3gs8BdIiJ50/whmmYkcAQwBpjXUewiciJwPHCA\nqg4H9gDu7+vfU2lEJFWqeanqk8AGIrJHqeY5kGq60EVkQ+AHwKmq+mdVXa2qLap6p6qeE02znojM\nEpH3otesjpZRRE4SkUc7zfM/rbSIXC8iV4hIGLWaT4jIhGjcw9Fbno9ay2O7iPhRYKWqLuxiXEGi\nv2ku8ClgLyDTxTQtqvoicCzwPm7FADAFuEdVF0TTLVbV2d0tS0TGicifReR9EVkuIpdHwyeIyAPR\nsGUi8nsRGRGNuxG3cr0z+hy+HQ2fKiKPi8hKEXk+f9NaRLYSkYejz/S+6DP+Xd74T0Wb4yujrZsd\n8sblROQ7IvIvYLWIpPK3KEQkEW39LIjy3ioiI6Nxg0Xkd9HwlSLylIiMzvsI5nb1+VaDmi503Bd/\nMHBbD9OcB0wFdgF2BvYEzi9iGZ8FLgQ2At4AfgSgqvtG43dW1eGq2tUm8U7Aq0Usq1uq+jbwNPCx\nHqZpA+7Im+afwAkico6I7CEiye7eG437K/AWkAbGArd0jAZ+AmwO7ACMA2ZGyzweeBs4LPocLhKR\nsUCI2xQeCZwNzBGRTaL53QQ8CWwczef4vBzbAjcDZwKbAHfhViKD8uIehyvIEara2ulPOR34NDA9\nyrsCuCIadyKwYZR/Y+AUYG3ee1/GfUeqTq0X+sbAsi7+2fk+D/xAVZeq6vu4oj2+h+k7u01Vn4yW\n8XvcCqNQI4DGLoZfFrUoK0VkJa7ACvEernAKmkZVf4f74h8EPAQsFZHvdPO+PXGFcU60FbFOVR+N\n5vOGqt6rqk3RZ/hzXCF15wvAXap6l6q2q+q9uJXUISIyHrel8X1VbY6W8Ze89x4LhNHyWoCfAUOA\nvfOmuUxV3+k47tHJKcB5qrpQVZtwK5Kjos38Ftx3ZqKqtqnqPFVtyHtvI+5/VnVqvdCXA6N62Vfb\nHNdKdXgrGlaoxXk/rwGGF/HeFcD6XQw/Q1VHdLyAQwuc31jgg2KmUdXfq+oBuC/wKcD/ishBXbxv\nHPBWVytNERktIreIyLsi0oA75jCqhwxbAkd3WplNwx1v2Bz4QFXX5E3/Tt7PH/p/qWp7NH5sN9N3\ntezb8pb7MtCGO35zI3APcEu0G3eRiNTlvXd9YGUP865YtV7o/wCacJtq3XkP98/vMD4aBrAaGNox\nQkTGlDjfv4BtSzEjERkH7A480sM0CeCwrqaJ9uP/GGXasYu3vwOM72al+WNAgZ1UdQNci51/ULDz\nLZLvADfmr8xUdZiqZoFFwEgRGZo3/bi8nz/0/4oOPo4D3u1heZ2XfXCnZQ9W1Xejz+BCVf0Ibgvh\nUOCEvPfuADzfw7wrVk0XuqrWA98HrhCRT4vIUBGpE5GDReSiaLKbgfPFnc8eFU3fceDneWCSiOwi\nIoOJ9juLsATYuofxTwIjon3WPon+pum4fe8ncfusnadJRQesbsYdef95NPwkEcmIyPrRQaqDgUnA\nE91kXQRkRWRYdOBqn2jc+sAqoD76W87p9N7On8PvgMNE5CARSUbzmiEiW6jqW7jN+JkiMkhE9sKt\nnDrcCmREZP+otf0WbmX+eIEf2a+AH4nIltFnsImIHB79vJ+I7BQdj2jAbcq35713OnB3gcupLKpa\n8y/cfvjTuBZ6Me5A0N7RuMHAZbgv8aLo58F57z0PWIZrCb6Aay0mRuOuB36YN+0MYGHe76dE81wJ\nHNNNtouB7+T9Phf4cqdpOs93LrAOt8/YCDwb5czPPRP3RV0V/d2v404rjs2b5kjgMdwuRAMwHzip\nh89xPHA7bpdoGW5fGNzKYV60rOdwxZef93DcAbmVwNnRsI/ijgt8gDsTEALjo3ETcFsdjbjTfbOB\na/LmdwTwElAfzWNS3rgc7nQhXQ3DNW5n4Q6CNgILgB9H446Lhq/GrZwuA1LRuCnAM76/y319SfRH\nGE+iI82PALtq1wePYk/cRTyvqOoFHjPMwa1s/t8WUzWwQjcVR0Sm4Fr6fwOfwG1F7KWqz3oNVsVK\nduWQMSU0Bvgz7lTXQuBrVuT9Yy26MTFQ00fdjTGOFboxMWCFbkwMWKEbEwNW6MbEgBW6MTFghW5M\nDFihGxMDVujGxIAVujExYIVuTAxYoRsTA1boxsSAFboxMWCFbkwMWKEbEwNW6MbEgBW6MTFghW5M\nDFihGxMDVujGxIAVujExYIVuTAxYBw4xkQ7COlyHCMOj17BOPw8DWnH9jnX015b/cwPwQS6bsY4A\nqpB14FBD0kG4Aa6Dwo7X1nk/jwOS/VzEOlxniW/jOi58LXq9CizIZTMt/Zy/KRMr9CoVtdC7AVNx\nPZPuiStoX5pwPao+huvC+PFcNrPUYx6Txwq9SqSDMAHsBewP7Bv9PNRrqN69gSv6x4B7ctnMW57z\nxJYVegVLB2ESmA4chesTfIzfRP32NDAHmJPLZl73HSZOrNArTLRJfgDwGeBwYJTfRGUzH1f0f8pl\nMy/6DlPrrNArRDoIJwCnAScCG3mOM9BeAK4AbsxlM6t9h6lFVugepYNQgE8ApwMHY9c1rASuBa7I\nZTNv+g5TS6zQPUgH4XBcy30asL3nOJWoHQiBX+aymXt9h6kFVugDKCrws4FvAht4jlMtXgQuxO3L\n25e1j6zQB0B0gO0U4HxgU89xqtWzwPdy2UzoO0g1skIvo2gf/LPAD3FXqZn+exg4K5fNzPMdpJpY\noZdJOggPAH6Ku3rNlJYCNwHfzWUz7/gOUw2s0EssHYSjgV8CR/vOEgOrgO8AV9n+e8+s0EsoHYRf\nAi4mfufBfZsLfDmXzSzwHaRSWaGXQDoItwCuwZ0TN36sAc7FnZJr9x2m0lih91M6CE8ALgVG+M5i\nAHcDzRdz2cxrvoNUEiv0PkoH4TBcK36s7yzm/1kLnJrLZq7zHaRSWKH3QXRd+m3ATr6zmB5dBXzD\nHohhhV60dBAeBNyMHXCrFo8CR+eymcW+g/gU95soipIOwu8Cd2FFXk2mAfPSQTjVdxCfrEUvQHSN\n+nW4B0CY6tQMnJbLZn7jO4gPVui9SAfhxsDfsSvcasVPc9lM4DvEQLNC70E6CMcA9wGTfGcxJfVL\n3EG62Hz5rdC7kQ7C8cD9wETfWUxZXAN8NS4X11ihdyE6ffYAMN53FlNWNwMn5LKZVt9Bys0KvZN0\nEH4Et7m+me8sZkDcDhyby2aafQcpJyv0PFGRP0TtPnnVdO1u4PBavrDGzqNH0kG4Ge4fbkUePwcD\n10cPCqlJVuj857r1v2L75HH2OeBnvkOUS+wLPeoN5VbsPLmBs9JBeKbvEOUQ+0LHdRxwiO8QpmJc\nkg7Cw3yHKLVYF3o6CAPgZN85TEVJADelg3AX30FKKbZH3dNBeASu76+aPQBj+mUhsEsum1nuO0gp\nxLJFTwfh1ribVKzITXe2wHUPVRNiV+jpIByEO/i2oe8spuJ9Kh2Ep/kOUQqxK3TgImB33yFM1bg4\nHYSTfYfor1jto0dPh7kb22Q3xXkZ2COXzazxHaSvYtOip4NwFLZfbvpmB2CW7xD9EZtCB36N3ahi\n+u4r6SA80neIvorFpns6CA8F7vSdw1S9d4Htc9nMKt9BilXzLXo6CNejyje7TMUYC3zfd4i+qPlC\nB74NTPAdwtSMM9NBuIPvEMWq6UJPB2Ea+K7vHKam1OGeOVdVarrQgV8AQ3yHMDVn/3QQVlW32DV7\nMC46Z/433zlMzVqIOzC32neQQtRki54OwgR2AM6U1xa44z9VoSYLHTgG2N53CFPzzkgH4Qa+QxSi\n5go9eu7Xub5zmFgYAZzqO0Qhaq7QgcOw7ozNwPlmOgiH+g7Rm1os9PN8BzCxsgnwVd8helNwoYvI\nPBE5VUQqtsvgdBAeCOzpO4eJnbOj5xxUrGJa9GOBzYGnROQWETlIRCrtTjBrzY0PY4GTfIfoSdHn\n0UUkARwKXAW04W79vFRVPyh9vMKlg3BP4AmfGUysLQC2qdQeWovaRxeRycAlwMW4ByseDTTgOiT0\n7Uu+A5hYmwB83HeI7qQKnVBE5gErcd3NBqraFI16QkT2KUe4QqWDcDBu18IYn76C62q74hTUokeb\n63NUdX9VvSmvyAFQVd835B+BPezR+PfpdBBu7DtEVwoqdFVtB8pWzCJyrYgsFZEX+jiLk0qZx5g+\nWg/Xh1vFKWYf/T4ROVtExonIyI5XiXJcD3yyL29MB+EWwAElymFMf33Bd4CuFHt67VTgYWBe9Hq6\nFCFU9WGgr0ftT6A2L/wx1WnPdBBO9B2is4IPxqnqVuUM0g8n+A5gTCefBy70HSJfMVfG1YnIGSLy\np+h1mojUlTNcb9JBuD2wnc8MxnThUN8BOitmk/cqXA8nV0av3aNhPmU8L9+YruxWaUffC950B6ao\n6s55vz8gIs+XOlCRrF9zU4kSwIHALb6DdCimRW8Tkf88TVVEtsZdAttvInIz8A9gOxFZKCK9XuWW\nDsLhwMdKsXxjyuAg3wHyFdOinwM8KCJv4ro12hL4n1KEUNXj+vC2fXFP5DSmEn3Cd4B8Bbfoqno/\nsA1wBnA6sJ2qPliuYAXY3+OyjenN5ukg3NF3iA7FXOve+cq4iSJSD8xX1aWljVWQir2BwJjIQUBf\nr/YsqWI23b8E7AV0tOIzcBfNbCUiP1DVG0ucrVvpIFwf2LnXCY3xawbubk/viin0FLCDqi4BEJHR\nwG+Bj+KulhuwQgcmY90fm8pXMY1RMUfdx3UUeWRpNOwDoKW0sXpVMR+gMT0Ylw7CEb5DQHEt+lwR\n+Svwx+j3o6Jhw3D3qQ+kyQO8PGP6ajJui9erYgr9VNytqtOi32/A3aOuwH6lDtYLK3RTLXammgpd\nVVVEngbqVfU+ERkKDAcay5auC1EHDfbcdlMtKqJRKuamlq8AfwJ+HQ0aC9xejlC92Bq3gjGmGlTE\n8aRiDsadCuyDexgkqvo6sGk5QvWiItaQxhRoUtTpp1fFBGhS1eaOX0QkBfh4tG2l3hdvTFeG4qdB\n/JBiCv0hETkXGCIiB+KOvt9Znlg9Gu1hmcb0h/fvbDGFHgDvA/OBk4G7VNVHzyjePzRjiuT9O1vM\n6bXTVfVS4DcdA0TkG9GwgeT9QzOmSN6/s8W06Cd2MeykEuUohvcPzZgief/O9tqii8hxuGdVbyUi\nf8kbtT59f3Jrf3j/0IwpkvfvbCGb7o8Di4BRfPhOnEbgX+UI1Z3oYhnvRzCNKVLlF7qqvgW8hbtF\n1beNKO64gjGVwHvjVMyVcVNF5CkRWSUizSLSJiIN5QzXhYrubN6YbgzxHaCYg3GXA8cBr+OCfxm4\nohyhjKkxSd8Biro0T1XfAJKq2qaq19HH/tKMiRnvu5vFBFgjIoOA50TkItwBOu/X8JpS0fbD6+7/\nB6mGdYuSKZalkqxIkliTVO+tUbVTTb1dSF8jIjIO99Sm0bjLy2eX6jqVYgr9eFxhnwZ8ExgHfKYU\nIUwlkMSDLVN3vFoueW5K+6vTpNVtbrZAy4pkcuX7yWT90lRy9eJkcu3iVKplcSrZ/n4yKR8kE8mG\nRGK91YnE0CaRDdpgBCJ2d+GHFdoZaSvwLVV9RkTWB+aJyL2q+lJ/AxRT6MuAZlVdB1woIklcf9Cm\nRjQwfMNjmi+Yvou88eoNg7JNG8qayXVQt2lb2yabtrVtMqm593kANEPT8mRyxfupZMOSZHL1klRq\n3eJUsmVJMqlu5ZBMNSQSg9ckZGizWzlshIj3A1ZlVFBHJ6q6CLeljKo2isjLuNvBB7TQ78f1Q74q\n+n0I8Hdg7/6GMJXlOZ243c5NV/P15B2PfSt16zZJ0aJODw2C9TZraxuzWVvbmELfs1Zk7QfJxIr3\nk8nGJanU6sXJ5LrFqWTrklRK308mZUUyUdeQSAxeKzK0WWTDdrdyqJaGZl2xbxCRNLAr8EQpAhRT\n6INVtaPIUdVV0VNmBlJJuoAyhbmy7fB9ftt2YMPsup8/tFfipX1EyndQaYjqkLGtbUPGtrZBU2Gb\nDqtFVi9PJlcuTSYblqSSaxanUk2LU8nWpclk+7JkMrkimahrdCuHYS3/XTn46N1nTTETi9v1mQOc\nqaolOYVdzD9utYjspqrPRGF2B9aWIkQRBvohlLG3iqEbfK7l/Ok7yZuv/3ZQdvVGsmoX35k6DFMd\nNqy1ddj41taxNBX2noaENEQrh8YlqeSaJclUs9tySLI8mUysSCQHrUrIkLWSGNYibKhu5dDfA5IF\nP24t6op8DvB7Vf1zP5f73/m6ZzsWFGAKrnfI93DPVB8DHKuq80oVphDpIKwHNhjIZZr/+koyfDxI\n3bR1UrTgzfJqpqANiUTDsmRi5dJkqnFxKrl2cSrZtDiValuaTLI8mUyuTCTqVidk6NpEYngrbKju\ngGT+GanZ80+cf3JvyxIRwT109QNVPbOUf0fBhR4FqQO2i359VVVb8sYdqKr3ljJcV9JBuAD33Djj\nyTDWNl5VN+uZjyXm7y1iHV121g7tKxOJlcuSyfolqeSqxkTixkPOWXRxb+8TkWnAI7hnPrRHg89V\n1bv6m6moQu9xRiLPqOpuJZlZD9JB+E9c7zDGsx3krQU3DvpJ/ShpKPv/vcqdwcz6X/oMUMoLXgaq\ni6T3Bmg5phcv65YT9mj61W4XtJzwj1ZNLPKdp4J5/2xKWegD9aDIdwdoOaZAN7R9cq/JTVdvcH/b\nrg+pUuDZ9lipqUIfKFboFWgNg4d9qeWc6Qc1//TdpTqi0CvB4qKmCj1XwnlVwnJMH7ym47bas+nK\nPc5t+eI/WzWx0HeeCtBKBTROvRa6iEwRkTF5v58gIneIyGUiMrJjuKoeWa6QncwfoOWYfrip7YCp\nOzZds/Hf2qbMVS30LHdNeoWZ9d7//kJa9F+D2+8SkX2BLO4Om3pgdvmidetViPUXp2qsY70hp7R8\nc8b+zT9bvEhHPuU7jyfP+A4AhRV6MuoDHeBY3K1zc1T1e8DE8kXrWi6baaUEF/mbgfOmbr7lXk2X\nTzmn5atPtWjybd95Blj1FHrU/RLA/sADeeN83VA/oA+lNKXxx7YZU3ZsumbTO9umzlUd8Munfama\nQr8Z1x3THbhr2x8BEJGJuM13H573tFzTT00MGnx6yxkzZjT/fPlCHVWSO7MqmALP+g4BBV4ZJyJT\ngc2Av6vq6mjYtsDwjptcBlI6CPcH7hvo5ZrS+3Ti0acvqps9apC0pn1nKYPXmFm/Xe+TlV9Bp9dU\n9Z/AG8AhInK0iOyoqq/5KPKIteg14vb2aXvs2HTNZn9umzZXtbjbOatARWy2Q2Gn1zYUkbnA7bge\nWz4P3CEiD4qIl7vIctnMMuA1H8s2pddM3XpntXx9xr7Ns1a81b7pP33nKaHqKXTgf3HPvNpGVY9Q\n1U8D2wBPAT8qZ7he3ONx2aYM3tFNx05vnjX11OYz5jVp6t++85RAVRX6AUCgqh23zRH9fG40zhcr\n9BoVtk/dfVLTtVv8oXX6XNX/PLqs2jQDT/oO0aGQQm9W1dbOA6NhPi9cmQt2A0WtaiVV953Wk2fs\n03RZ45vtmz3uO08fPMzM+oKfLFNuhRT6YBHZVUR26/TaHY9Pgc1lM6uBx3wt3wyM9xi12cebL9n7\n5OYzn12ndQt85ynCX30HyFfIBS+LgJ93M25xCbP0xT3Afp4zmAFwT/ueu05q2r31wtT1D30+ef9u\nIqzvO1Mv7ixkIhH5JHAprtumq1U1W44wJXvCjA/pINyFCrkgwQycMXyw5LeDfvLGtol39/GdpRuv\nMLN+h94mivpGeA04EFiIO8B9XCk6bOisoEtYRWRj3Km17aNBLwM35V0D78vzuFsAx3rOYQbQYkaO\n/kTzxaP3Szz7/JV1lw4ZIs3b+s7USaFPb90TeENV3wQQkVuAwynDvRyFnEffAXgB2B239nkdmAK8\nICLb9/TecstlMwr83mcG48+D7bvuPKnp2gnXtR70kKq3y7G78ocCpxsLvJP3+0LK1GgVeh79G6p6\nkqpeqqqzVPVE4HT8nkfvcL3vAMafdhLJC1tPnP7RpiuaX2of/5jqgD3SrDuvMLO+4m66KqTQd1LV\nWzsPVNU5wI6lj1ScXDbzMhV0vtL4sZSNNjmkObvPCS3BC2t0vVc8Rim0NQe32zku7/ctKNPTaAop\n9NV9HDeQrvMdwFSGR9on7zSp6ZptZ7ce8nC7eunZ55Yipn0K2EZEtoq6JP8s8JdyhOr1qLuILKTr\n02uC6xtqXBfjBlQ6CEfgTgMO9p3FVI6R1C+/ftBFL+0k/54mMiCPI7+PmfUHFvMGETkEmIU7vXat\nqpZld7iQQr+gp/GqemFJE/VROghvwT0Bx5gPmZp48cWr6y6R4bLuI2Ve1MHMrP9bmZfRJ1V9Hj1f\nOggPAiryQzb+Ce3tZ6dufexryTsnJURH9v6Oor3AzPqdyjDfkiikRb+sp/GqekZJE/VROggFdxqw\n3GttU8VG0Lji2kEXz99V3pgmUtLHnX+RmfUVe6yokEI/Me/XC4EPbcqr6g1lyNUn6SD8H+Ba3zlM\n5Zsir7x8zaCL2zaQtaU4c7QY2JKZ9RV7k1Wxvak+q6q7ljFPv6SDcBDwJnalnCmI6pmpOY+dkbxt\n+4ToqH7M6Hxm1lfCNSXdKnbTpaJ36HPZTDNwie8cplqIzGo9atouTb+ue7J9u4dUaevDTNYAV5U6\nWalVY99rvfkVsMR3CFM9Ghi+4THNF0w/svnCN+p1aLFXtV3PzHrf93z0qpBr3RtFpEFEGoDJHT93\nDB+AjEXJZTNrgYt85zDV51ndZrudm36z08UtxzzapvJ+AW9pB35R7lylUDOn1/Klg3AIbl99TG/T\nGtOV9VldP7vuF89PTby0t0i3d3nOZmb9yQMarI9qstDBjsCb0pgsC16/YdBP12wkq3buNKoBmMjM\n+kJafu9qcR+9w/VALT062HjwL52wza5Ns3f+ccvnHmtTyT/288NqKXKo4RYdIB2Eu+FuHKjlFZoZ\nIMNY23hV3axnPpaYP1qEnSv5vHlnNV3oAOkgvBL4mu8cpnaMpOGQZ7LH3e07RzHi0NKdByzzHcLU\njNuqrcghBoWey2ZWAIHvHKYmrAIq4t6OYtV8oUeuBaqxEwBTWc7LZTMLfYfoi1gUevQQyc/jrz93\nU/3uAn7pO0RfxaLQAXLZTA44xXcOU5UWAydFDUZVik2hA+SymVuwi2hMcRQ4IZfNVM05867EqtAj\nZwA+nxJqqsvPctnMvb5D9FfsCj3qnPE4/PYEa6rDU7jTs1UvdoUOkMtmngO+7TuHqWiNwHG5bKbF\nd5BSiGWhA+SymcuAq33nMBWpFTgql81UUzfNPYptoUe+hut62Zh8p+Symb/7DlFKsS70XDbTChwN\nPOc7i6kYP8xlM9f4DlFqNX9TSyHSQbg57pZW773OGK9uzGUzJ/gOUQ6xbtE75LKZ94BDsCvn4uxB\n4Eu+Q5SLFXokl828AByJnXaLo/nAkbVyhL0rVuh5ctnMA8ARWLHHyTPAfrlsxkfPqwPGCr2TXDZz\nN/ApYJ3vLKbsHgc+nstmlvsOUm5W6F2ITq0cSuX0/25K7wHgE7lsJhbHZazQu5HLZu4H9gcq/uH8\npmh3AZnocuhYsELvQS6beQLYF3jPdxZTMnOAI3LZTKx2zazQe5HLZl4E9sIdtDHV7VLg2KiPvlix\nC2YKlA7CwcBs4HjfWUzRmoGv1+IVb4WyQi9SOgjPwPXY2l03PaayLAGOzmUzj/gO4pMVeh+kg3Bf\n4I/Apr6zmB49ChyTy2YW+Q7im+2j90Eum3kY2B33YAJTmX6BuxAm9kUO1qL3SzoIBwHnA9/FNuUr\nxdvAV3PZjN1+nMcKvQTSQbgLcB2wi+8sMabAr4Fv57KZRt9hKo0VeomkgzCF6xHme8Agz3Hi5t/A\nl6N7FUwXrNBLLB2EO+IeKT3Fd5YYUOBy4LtxusqtL6zQyyAdhEng67jWfRPPcWrVP4Czc9mMdbVV\nACv0MkoH4frA2cBZwHDPcWrFy8C5uWzmdt9BqokV+gBIB+Fo4PvAV4A6z3Gq1bvATOC6XDbT5jlL\n1bFCH0DpIJwA/Ag4BhDPcapFPZAFLs1lM2t9h6lWVugepINwB+CbuOvmB3uOU6lexR1ou8FOl/Wf\nFbpH6SDcBNfD68nAWM9xKoECdwOXAX+v5t5LK40VegWIzsEfhiv6A4nfZn0D7oKjy3PZzBu+w9Qi\nK/QKkw7C8bin0R4F7E3tFv06XOv9B+DOXDazxnOemmaFXsHSQbgZ7qm0nwGmA0m/ifqtEfgbcAeu\nuBs854kNK/QqkQ7CUbin0+6Ha+m39puoIC24J/M8DtwLPJDLZuxR2h5YoVepdBCOwRV8x2t3/F9j\nvxxX1I8DjwFPxe3ZbJXKCr1GpINwPWAyMBGYgGvxJ0SvzSndvn4T7iaSN4EFea9Xc9nM6yVahikx\nK/QYiJ53txWu4DfMew3DnccfDKyH6xd8Fe559qs6/dyIu9f73Vw20z7Af4LpJyt0Y2LAHiVlTAxY\noRsTA1boxsSAFboxMWCFbkyy5/8ZAAAAg0lEQVQMWKEbEwNW6MbEgBW6MTFghW5MDFihGxMDVujG\nxIAVujExYIVuTAxYoRsTA1boxsSAFboxMWCFbkwMWKEbEwNW6MbEgBW6MTFghW5MDFihGxMDVujG\nxIAVujExYIVuTAxYoRsTA1boxsSAFboxMWCFbkwMWKEbEwNW6MbEwP8BbLnYPUguIQEAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Iw6L0fotmdJk"
      },
      "source": [
        "### Split train and test data\n",
        "\n",
        " For practical prediction purposes,  we use the most recent round of survey data  as the testing  and the rest as the training data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6-IIX6ZBLLZD",
        "colab": {}
      },
      "source": [
        "# Year split \n",
        "mw_clust_test_cond =  mw_clust['FS_year']>2015\n",
        "mw_clust_train_cond =  mw_clust['FS_year']<2016\n",
        "mw_clust_test = mw_clust[mw_clust_test_cond]\n",
        "mw_clust_train = mw_clust[mw_clust_train_cond]\n",
        "\n",
        "\n",
        "tz_clust_test_cond =  tz_clust['FS_year']>2013\n",
        "tz_clust_train_cond =  tz_clust['FS_year']<2014\n",
        "tz_clust_test = tz_clust[tz_clust_test_cond]\n",
        "tz_clust_train = tz_clust[tz_clust_train_cond]\n",
        "\n",
        "ug_clust_test_cond =  ug_clust['FS_year']>2011\n",
        "ug_clust_train_cond =  ug_clust['FS_year']<2012\n",
        "ug_clust_test = ug_clust[ug_clust_test_cond]\n",
        "ug_clust_train = ug_clust[ug_clust_train_cond]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oVO_l3N3ow2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20f0c1d9-b642-4c6e-dddd-5d326bdda092"
      },
      "source": [
        "ug_clust_train.isnull().values.any()"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ioSj-n43xbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07d70220-9733-4638-ff4c-23e2b4a2c1f2"
      },
      "source": [
        "ug_clust_test.isnull().values.any()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWJ45aOV39wB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "186415df-0e62-4447-a7c6-678fcf4cb813"
      },
      "source": [
        "mw_clust.isnull().values.any()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w_YE97RELQ0n"
      },
      "source": [
        "**Separate the target/labels from the X variables. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ss3jWM1YKHRQ",
        "colab": {}
      },
      "source": [
        "labels = ['FCS', 'rCSI', 'HDDS']\n",
        "category_labels = ['FCS_category', 'rCSI_category', 'HDDS_category']\n",
        "\n",
        "\n",
        "mw_clust_y_train= mw_clust_train[['FCS_category', 'rCSI_category', 'HDDS_category']]\n",
        "mw_clust_y_test= mw_clust_test[['FCS_category', 'rCSI_category', 'HDDS_category']]\n",
        " \n",
        "mw_clust_X_test= mw_clust_test.drop(labels+category_labels+['FNID'],  axis=1)\n",
        "mw_clust_X_train= mw_clust_train.drop(labels+category_labels+['FNID'], axis=1)\n",
        "\n",
        "\n",
        "tz_clust_y_train= tz_clust_train[['FCS_category', 'rCSI_category', 'HDDS_category']]\n",
        "tz_clust_y_test= tz_clust_test[['FCS_category', 'rCSI_category', 'HDDS_category']]\n",
        "\n",
        "tz_clust_X_test= tz_clust_test.drop(labels+category_labels,  axis=1)\n",
        "tz_clust_X_train= tz_clust_train.drop(labels+category_labels, axis=1)\n",
        "\n",
        "\n",
        "ug_clust_y_train= ug_clust_train[['FCS_category', 'HDDS_category']]\n",
        "ug_clust_y_test= ug_clust_test[['FCS_category', 'HDDS_category']]\n",
        "\n",
        "ug_clust_X_test= ug_clust_test.drop(['FCS_category', 'FCS', 'HDDS', 'HDDS_category'],  axis=1)\n",
        "ug_clust_X_train= ug_clust_train.drop(['FCS_category', 'FCS', 'HDDS', 'HDDS_category'],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ-QpM6-fWyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def TreeCLF(X_train,y_train,X_test, y_test):\n",
        "    # Define tree classifier\n",
        "    tree_clf = DecisionTreeClassifier(random_state=66)\n",
        "    \n",
        "    max_depth = [int(x) for x in np.linspace(3, 20, num = 10)]\n",
        "    max_features = [int(x) for x in np.linspace(3, 20, num = 10)]\n",
        "    # n_estimators = [int(x) for x in np.linspace(1, 10, num = 5)]\n",
        "\n",
        "    random_grid = {#'n_estimators': n_estimators,\n",
        "                   'max_features': max_features,\n",
        "                   'max_depth': max_depth\n",
        "                   #'min_samples_split': min_samples_split\n",
        "                   #'min_samples_leaf': min_samples_leaf}\n",
        "                   #'bootstrap': bootstrap\n",
        "                    }\n",
        "    \n",
        "    tree_random = RandomizedSearchCV(estimator = tree_clf, param_distributions = random_grid,\n",
        "                                    n_iter = 30, cv = 3, verbose=2, random_state=666, n_jobs = -1)\n",
        "\n",
        "\n",
        "    tree_random.fit( X_train, y_train)\n",
        "\n",
        "    y_pred = tree_random.predict(X_test)\n",
        "    \n",
        "    # report = classification_report(y_test, y_pred)\n",
        "\n",
        "    \n",
        "    # Return accuracy\n",
        "    tree_test_score = round(tree_random.score(X_test, y_test), 3)\n",
        "    tree_train_score = round(tree_random.score(X_train, y_train), 3)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return y_pred,y_test\n",
        "    \n",
        "    # return report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYNCGR5MfWyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def rfCLF(X_train,y_train,X_test, y_test):\n",
        "\n",
        "    rf_clf = RandomForestClassifier(max_features='auto', n_estimators = 100,min_samples_split=10,warm_start=True)\n",
        "\n",
        "        \n",
        "    # Define rfc classifier\n",
        "    max_depth = [int(x) for x in np.linspace(3, 20, num = 10)]\n",
        "    max_features = [int(x) for x in np.linspace(3, 20, num = 10)]\n",
        "\n",
        "    random_grid = {#'n_estimators': n_estimators,\n",
        "                   'max_features': max_features,\n",
        "                   'max_depth': max_depth\n",
        "                   #'min_samples_split': min_samples_split\n",
        "                   #'min_samples_leaf': min_samples_leaf}\n",
        "                   #'bootstrap': bootstrap\n",
        "                    }\n",
        "    \n",
        "    rf_random = RandomizedSearchCV(estimator = rf_clf, param_distributions = random_grid,\n",
        "                                    n_iter = 30, cv = 3, verbose=2, random_state=666, n_jobs = -1)\n",
        "\n",
        "\n",
        "    # Fit the random search model\n",
        "    rf_random.fit(X_train, y_train)\n",
        "\n",
        "    # Return accuracy\n",
        "#     rf_test_score = round(rf_random.score(X_test, y_test), 3)\n",
        "#     rf_train_score = round(rf_random.score(X_train, y_train), 3)\n",
        "    \n",
        "    y_pred = rf_random.predict(X_test)\n",
        "    \n",
        "\n",
        "    # return rf_test_score \n",
        "    return y_pred,y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrFVrNryfWyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def XGBCLF(X_train,y_train,X_test, y_test):\n",
        "\n",
        "    # fit model on  training data\n",
        "    XGB_clf = XGBClassifier(silent=False, \n",
        "                          scale_pos_weight=1,\n",
        "                          learning_rate=0.3,  \n",
        "                          colsample_bytree = 0.4,\n",
        "                          subsample = 0.8,\n",
        "                          objective='binary:logistic', \n",
        "                          #objective='multi:softmax', \n",
        "                          #num_class=14,\n",
        "                          n_estimators=100, \n",
        "                          reg_alpha = 0.3,\n",
        "                          max_depth=5, \n",
        "                          gamma=10)\n",
        "    \n",
        "    max_depth = [int(x) for x in np.linspace(3, 20, num = 10)]\n",
        "    max_features = [int(x) for x in np.linspace(3, 20, num = 10)]\n",
        "\n",
        "    random_grid = {#'n_estimators': n_estimators,\n",
        "                   'max_features': max_features,\n",
        "                   'max_depth': max_depth\n",
        "                   #'min_samples_split': min_samples_split\n",
        "                   #'min_samples_leaf': min_samples_leaf}\n",
        "                   #'bootstrap': bootstrap\n",
        "                    }\n",
        "    \n",
        "    XGB_random = RandomizedSearchCV(estimator = XGB_clf, param_distributions = random_grid,\n",
        "                                    n_iter = 30, cv = 3, verbose=2, random_state=666, n_jobs = -1)\n",
        "\n",
        "\n",
        "    \n",
        "    # Fit the random search model\n",
        "    XGB_random.fit(X_train, y_train)\n",
        "\n",
        "    # Return accuracy\n",
        "    xgb_test_score = round(XGB_random.score(X_test, y_test), 3)\n",
        "    xgb_train_score = round(XGB_random.score(X_train, y_train), 3)\n",
        "    \n",
        "    # return xgb_test_score\n",
        "    \n",
        "    y_pred = XGB_random.predict(X_test)\n",
        "    \n",
        "\n",
        "    # return rf_test_score \n",
        "    return y_pred,y_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQdfoEQBfWyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0a7b03d5-a054-4783-a27a-8e9f808ea0fe"
      },
      "source": [
        "mw_clust_y_train['FCS_category'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1699\n",
              "1     461\n",
              "2      14\n",
              "Name: FCS_category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJxiyR2YfWyV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6a04bdb3-18e0-4dd6-9b4c-4932dcc72490"
      },
      "source": [
        "y_pred,y_test = TreeCLF (mw_clust_X_train,mw_clust_y_train['FCS_category'], mw_clust_X_test,mw_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.82       309\n",
            "           1       0.83      0.04      0.07       136\n",
            "\n",
            "    accuracy                           0.70       445\n",
            "   macro avg       0.77      0.52      0.45       445\n",
            "weighted avg       0.74      0.70      0.59       445\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    2.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmu3pWFrfWyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a2d98dc7-930d-4d46-c2ab-88e9b99b65fd"
      },
      "source": [
        "y_pred,y_test  = TreeCLF (mw_clust_X_train,mw_clust_y_train['HDDS_category'], mw_clust_X_test,mw_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.49      0.66       445\n",
            "\n",
            "    accuracy                           0.49       445\n",
            "   macro avg       0.50      0.24      0.33       445\n",
            "weighted avg       1.00      0.49      0.66       445\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    2.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efAlPsSpfWyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "aaf5ae9a-943f-42d5-e307-dce740e39ce7"
      },
      "source": [
        "y_pred,y_test  = TreeCLF (mw_clust_X_train,mw_clust_y_train['rCSI_category'], mw_clust_X_test,mw_clust_y_test['rCSI_category'] )\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.69      0.45       157\n",
            "           1       0.55      0.23      0.33       282\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.39       445\n",
            "   macro avg       0.30      0.31      0.26       445\n",
            "weighted avg       0.47      0.39      0.37       445\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xfMskxXfWyh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6a055bef-499b-460d-8bd9-06eeb475d608"
      },
      "source": [
        "y_pred,y_test  =  rfCLF (mw_clust_X_train,mw_clust_y_train['FCS_category'], mw_clust_X_test,mw_clust_y_test['FCS_category'] )\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.4s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   18.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      1.00      0.82       309\n",
            "           1       0.00      0.00      0.00       136\n",
            "\n",
            "    accuracy                           0.69       445\n",
            "   macro avg       0.35      0.50      0.41       445\n",
            "weighted avg       0.48      0.69      0.57       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nn8zJH_fWyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e201942b-ceef-4306-c2fd-a2ec6d71a8f9"
      },
      "source": [
        "y_pred,y_test  = rfCLF (mw_clust_X_train,mw_clust_y_train['HDDS_category'], mw_clust_X_test,mw_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   16.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.67      0.80       445\n",
            "\n",
            "    accuracy                           0.67       445\n",
            "   macro avg       0.50      0.34      0.40       445\n",
            "weighted avg       1.00      0.67      0.80       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDVl4FrPfWyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "968cfcf5-a92e-4c90-c90e-7c484e11395e"
      },
      "source": [
        "y_pred,y_test  =  rfCLF (mw_clust_X_train,mw_clust_y_train['rCSI_category'], mw_clust_X_test,mw_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   19.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.93      0.55       157\n",
            "           1       0.78      0.20      0.32       282\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.45       445\n",
            "   macro avg       0.39      0.38      0.29       445\n",
            "weighted avg       0.63      0.45      0.39       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aRIzyyJ_70qV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c5c12019-b1d8-41db-ef7b-2388d1813f5f"
      },
      "source": [
        "y_pred,y_test  = XGBCLF (mw_clust_X_train,mw_clust_y_train['FCS_category'], mw_clust_X_test,mw_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   44.4s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      1.00      0.82       309\n",
            "           1       0.00      0.00      0.00       136\n",
            "\n",
            "    accuracy                           0.69       445\n",
            "   macro avg       0.35      0.50      0.41       445\n",
            "weighted avg       0.48      0.69      0.57       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARKdfCI-hAA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f61abf29-4c46-498c-e0e3-f6e4c245fa7e"
      },
      "source": [
        "y_pred,y_test  =  XGBCLF (mw_clust_X_train,mw_clust_y_train['HDDS_category'], mw_clust_X_test,mw_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   34.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.66      0.79       445\n",
            "\n",
            "    accuracy                           0.66       445\n",
            "   macro avg       0.50      0.33      0.40       445\n",
            "weighted avg       1.00      0.66      0.79       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfD1dUt1hCra",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e6a79013-3019-4740-cf1d-faf610121611"
      },
      "source": [
        "y_pred,y_test  =  XGBCLF (mw_clust_X_train,mw_clust_y_train['rCSI_category'], mw_clust_X_test,mw_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   33.3s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.55      0.57       157\n",
            "           1       0.74      0.79      0.77       282\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.69       445\n",
            "   macro avg       0.45      0.45      0.45       445\n",
            "weighted avg       0.68      0.69      0.69       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC_JeJo-1N8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fc98071-7fab-4a37-c802-1ddc8fa5285d"
      },
      "source": [
        "y_pred,y_test = TreeCLF (tz_clust_X_train,tz_clust_y_train['FCS_category'], tz_clust_X_test,tz_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = TreeCLF (tz_clust_X_train,tz_clust_y_train['HDDS_category'], tz_clust_X_test,tz_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = TreeCLF (tz_clust_X_train,tz_clust_y_train['rCSI_category'], tz_clust_X_test,tz_clust_y_test['rCSI_category'] )\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred,y_test  =  rfCLF (tz_clust_X_train,tz_clust_y_train['FCS_category'], tz_clust_X_test,tz_clust_y_test['FCS_category'] )\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = rfCLF (tz_clust_X_train,tz_clust_y_train['HDDS_category'], tz_clust_X_test,tz_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred,y_test  =  rfCLF (tz_clust_X_train,tz_clust_y_train['rCSI_category'], tz_clust_X_test,tz_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred,y_test  = XGBCLF (tz_clust_X_train,tz_clust_y_train['FCS_category'], tz_clust_X_test,tz_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred,y_test  =  XGBCLF (tz_clust_X_train,tz_clust_y_train['HDDS_category'], tz_clust_X_test,tz_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  =  XGBCLF (tz_clust_X_train,tz_clust_y_train['rCSI_category'], tz_clust_X_test,tz_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94       342\n",
            "           1       0.50      0.02      0.04        43\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.89       386\n",
            "   macro avg       0.46      0.34      0.33       386\n",
            "weighted avg       0.84      0.89      0.84       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.02      0.05        82\n",
            "           1       0.79      0.99      0.88       304\n",
            "\n",
            "    accuracy                           0.79       386\n",
            "   macro avg       0.65      0.51      0.46       386\n",
            "weighted avg       0.73      0.79      0.70       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    0.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.83      0.73       227\n",
            "           1       0.58      0.37      0.45       153\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.63       386\n",
            "   macro avg       0.41      0.40      0.39       386\n",
            "weighted avg       0.61      0.63      0.61       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   22.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94       342\n",
            "           1       0.00      0.00      0.00        43\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.89       386\n",
            "   macro avg       0.30      0.33      0.31       386\n",
            "weighted avg       0.79      0.89      0.83       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   22.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        82\n",
            "           1       0.79      1.00      0.88       304\n",
            "\n",
            "    accuracy                           0.79       386\n",
            "   macro avg       0.39      0.50      0.44       386\n",
            "weighted avg       0.62      0.79      0.69       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   22.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.88      0.74       227\n",
            "           1       0.57      0.28      0.38       153\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.63       386\n",
            "   macro avg       0.40      0.39      0.37       386\n",
            "weighted avg       0.60      0.63      0.58       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   33.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93       342\n",
            "           1       0.41      0.21      0.28        43\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.88       386\n",
            "   macro avg       0.44      0.39      0.40       386\n",
            "weighted avg       0.85      0.88      0.86       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   31.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.23      0.33        82\n",
            "           1       0.82      0.95      0.88       304\n",
            "\n",
            "    accuracy                           0.80       386\n",
            "   macro avg       0.70      0.59      0.61       386\n",
            "weighted avg       0.77      0.80      0.77       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   36.9s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.81      0.73       227\n",
            "           1       0.56      0.38      0.45       153\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.63       386\n",
            "   macro avg       0.41      0.40      0.39       386\n",
            "weighted avg       0.61      0.63      0.61       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avVDgEmM2JV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d5ef202-cdfc-416a-f385-8e106674de2b"
      },
      "source": [
        "y_pred,y_test = TreeCLF (ug_clust_X_train,ug_clust_y_train['FCS_category'], ug_clust_X_test,ug_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = TreeCLF (ug_clust_X_train,ug_clust_y_train['HDDS_category'], ug_clust_X_test,ug_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred,y_test  =  rfCLF (ug_clust_X_train,ug_clust_y_train['FCS_category'], ug_clust_X_test,ug_clust_y_test['FCS_category'] )\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = rfCLF (ug_clust_X_train,ug_clust_y_train['HDDS_category'], ug_clust_X_test,ug_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "y_pred,y_test  = XGBCLF (ug_clust_X_train,ug_clust_y_train['FCS_category'], ug_clust_X_test,ug_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "y_pred,y_test  =  XGBCLF (ug_clust_X_train,ug_clust_y_train['HDDS_category'], ug_clust_X_test,ug_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       334\n",
            "           1       0.42      0.37      0.39        97\n",
            "           2       1.00      0.11      0.20         9\n",
            "\n",
            "    accuracy                           0.74       440\n",
            "   macro avg       0.74      0.45      0.48       440\n",
            "weighted avg       0.73      0.74      0.73       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        49\n",
            "           1       0.88      1.00      0.94       389\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.88       440\n",
            "   macro avg       0.29      0.33      0.31       440\n",
            "weighted avg       0.78      0.88      0.83       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   13.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.96      0.87       334\n",
            "           1       0.46      0.16      0.24        97\n",
            "           2       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.77       440\n",
            "   macro avg       0.42      0.38      0.37       440\n",
            "weighted avg       0.70      0.77      0.71       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   12.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        49\n",
            "           1       0.88      1.00      0.94       389\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.88       440\n",
            "   macro avg       0.29      0.33      0.31       440\n",
            "weighted avg       0.78      0.88      0.83       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   26.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.96      0.86       334\n",
            "           1       0.41      0.12      0.19        97\n",
            "           2       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.76       440\n",
            "   macro avg       0.40      0.36      0.35       440\n",
            "weighted avg       0.69      0.76      0.70       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   18.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        49\n",
            "           1       0.88      1.00      0.94       389\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.88       440\n",
            "   macro avg       0.29      0.33      0.31       440\n",
            "weighted avg       0.78      0.88      0.83       440\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_VPhxlh2Xxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "626274c3-1153-40ad-dfe7-585a00072a2b"
      },
      "source": [
        "ug_clust_y_train.isnull().values.any()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2D2l3lj2zHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39208728-1cc9-4b69-c08d-53ea5cbe896f"
      },
      "source": [
        "tz_clust_X_train.isnull().values.any()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "abWsB5nGWfra"
      },
      "source": [
        "### downsample / oversample \n",
        "\n",
        "Using simpler metrics like accuracy_score can be misleading. In a dataset with highly unbalanced classes, if the classifier always \"predicts\" the most common class without performing any analysis of the features, it will still have a high accuracy rate, obviously illusory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CYrYYplPWmyp"
      },
      "source": [
        "Resampling\n",
        "A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and / or adding more examples from the minority class (over-sampling).\n",
        "\n",
        "Despite the advantage of balancing classes, these techniques also have their weaknesses (there is no free lunch). The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfitting. In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mx78w6b7XXT6",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "X = pd.concat([mw_clust_X_train, mw_clust_y_train['rCSI_category']], axis=1)\n",
        "\n",
        "\n",
        "not_crisis = X[X.rCSI_category==0]\n",
        "crisis = X[X.rCSI_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "crisis_upsampled = resample(crisis,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(not_crisis), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "upsampled = pd.concat([not_crisis, crisis_upsampled])\n",
        "\n",
        "upsampled_y_train = upsampled[\"rCSI_category\"]\n",
        "\n",
        "upsampled_X_train = upsampled.drop(\"rCSI_category\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgsxm2vsHwAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "1b77b80f-c0df-469d-8045-d8d76433cb30"
      },
      "source": [
        "y_pred,y_test  = rfCLF (upsampled_X_train,upsampled_y_train, mw_clust_X_test,mw_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   24.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.87      0.56       157\n",
            "           1       0.77      0.32      0.45       282\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.51       445\n",
            "   macro avg       0.40      0.40      0.34       445\n",
            "weighted avg       0.64      0.51      0.48       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tuAAE00HqY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "3d5c1a6e-3185-4af8-bc09-4dca33d4ee50"
      },
      "source": [
        "y_pred,y_test  = XGBCLF (upsampled_X_train,upsampled_y_train, mw_clust_X_test,mw_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.56      0.59       157\n",
            "           1       0.75      0.80      0.78       282\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.71       445\n",
            "   macro avg       0.46      0.46      0.45       445\n",
            "weighted avg       0.69      0.71      0.70       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQ6T4cuHMdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "07db6c6a-9351-499a-c08d-604e85b4cfb9"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "HDDS_df = pd.concat([mw_clust_X_train, mw_clust_y_train['HDDS_category']], axis=1)\n",
        "\n",
        "\n",
        "HDDS_not_crisis = HDDS_df[HDDS_df.HDDS_category==0]\n",
        "HDDS_crisis = HDDS_df[HDDS_df.HDDS_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "HDDS_crisis_upsampled = resample(HDDS_crisis,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(HDDS_not_crisis), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "HDDS_upsampled = pd.concat([HDDS_not_crisis, HDDS_crisis_upsampled])\n",
        "\n",
        "HDDS_upsampled_y_train = HDDS_upsampled[\"HDDS_category\"]\n",
        "\n",
        "HDDS_upsampled_X_train = HDDS_upsampled.drop(\"HDDS_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (upsampled_X_train,upsampled_y_train, mw_clust_X_test,mw_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (upsampled_X_train,upsampled_y_train, mw_clust_X_test,mw_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   25.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.13      0.23       445\n",
            "\n",
            "    accuracy                           0.13       445\n",
            "   macro avg       0.50      0.07      0.12       445\n",
            "weighted avg       1.00      0.13      0.23       445\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.68      0.81       445\n",
            "\n",
            "    accuracy                           0.68       445\n",
            "   macro avg       0.50      0.34      0.40       445\n",
            "weighted avg       1.00      0.68      0.81       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoKf2MsrMdys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "86e27d71-be36-4126-8aa3-cb37e0e414af"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "FCS_df = pd.concat([mw_clust_X_train, mw_clust_y_train['FCS_category']], axis=1)\n",
        "\n",
        "\n",
        "FCS_not_crisis = FCS_df[FCS_df.FCS_category==0]\n",
        "FCS_crisis = FCS_df[FCS_df.FCS_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "FCS_crisis_upsampled = resample(FCS_crisis,\n",
        "                                 replace=True, # sample with replacement\n",
        "                                 n_samples=len(FCS_not_crisis), # match number in majority class\n",
        "                                 random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "FCS_upsampled = pd.concat([FCS_not_crisis, FCS_crisis_upsampled])\n",
        "\n",
        "FCS_upsampled_y_train = FCS_upsampled[\"FCS_category\"]\n",
        "\n",
        "FCS_upsampled_X_train = FCS_upsampled.drop(\"FCS_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (upsampled_X_train,upsampled_y_train, mw_clust_X_test,mw_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (upsampled_X_train,upsampled_y_train, mw_clust_X_test,mw_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   24.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.95      0.87       309\n",
            "           1       0.82      0.46      0.59       136\n",
            "\n",
            "    accuracy                           0.80       445\n",
            "   macro avg       0.81      0.71      0.73       445\n",
            "weighted avg       0.81      0.80      0.79       445\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.43      0.59       309\n",
            "           1       0.42      0.93      0.58       136\n",
            "\n",
            "    accuracy                           0.59       445\n",
            "   macro avg       0.68      0.68      0.59       445\n",
            "weighted avg       0.78      0.59      0.59       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgtMEBk-Nqo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "13e805bc-525f-479f-f6d1-6aad8ec5d2d8"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "HDDS_df = pd.concat([tz_clust_X_train, tz_clust_y_train['HDDS_category']], axis=1)\n",
        "\n",
        "\n",
        "HDDS_not_crisis = HDDS_df[HDDS_df.HDDS_category==0]\n",
        "HDDS_crisis = HDDS_df[HDDS_df.HDDS_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "HDDS_crisis_upsampled = resample(HDDS_crisis,\n",
        "                                 replace=True, # sample with replacement\n",
        "                                 n_samples=len(HDDS_not_crisis), # match number in majority class\n",
        "                                 random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "HDDS_upsampled = pd.concat([HDDS_not_crisis, HDDS_crisis_upsampled])\n",
        "\n",
        "HDDS_upsampled_y_train = HDDS_upsampled[\"HDDS_category\"]\n",
        "\n",
        "HDDS_upsampled_X_train = HDDS_upsampled.drop(\"HDDS_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (HDDS_upsampled_X_train,HDDS_upsampled_y_train, tz_clust_X_test,tz_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (HDDS_upsampled_X_train,HDDS_upsampled_y_train, tz_clust_X_test,tz_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   13.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.84      0.55        82\n",
            "           1       0.94      0.66      0.78       304\n",
            "\n",
            "    accuracy                           0.70       386\n",
            "   macro avg       0.67      0.75      0.66       386\n",
            "weighted avg       0.83      0.70      0.73       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.6s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   29.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.84      0.54        82\n",
            "           1       0.94      0.65      0.77       304\n",
            "\n",
            "    accuracy                           0.69       386\n",
            "   macro avg       0.67      0.75      0.66       386\n",
            "weighted avg       0.82      0.69      0.72       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2XYCANhNr7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "3b3b6aaa-18bc-4a62-f4cc-17e5aef5eea8"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "FCS_df = pd.concat([tz_clust_X_train, tz_clust_y_train['FCS_category']], axis=1)\n",
        "\n",
        "\n",
        "FCS_not_crisis = FCS_df[FCS_df.FCS_category==0]\n",
        "FCS_crisis = FCS_df[FCS_df.FCS_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "FCS_crisis_upsampled = resample(FCS_crisis,\n",
        "                                replace=True, # sample with replacement\n",
        "                                n_samples=len(FCS_not_crisis), # match number in majority class\n",
        "                                random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "FCS_upsampled = pd.concat([FCS_not_crisis, FCS_crisis_upsampled])\n",
        "\n",
        "FCS_upsampled_y_train = FCS_upsampled[\"FCS_category\"]\n",
        "\n",
        "FCS_upsampled_X_train = FCS_upsampled.drop(\"FCS_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (FCS_upsampled_X_train,FCS_upsampled_y_train, tz_clust_X_test,tz_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (FCS_upsampled_X_train,FCS_upsampled_y_train, tz_clust_X_test,tz_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   29.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.92       342\n",
            "           1       0.39      0.44      0.41        43\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.86       386\n",
            "   macro avg       0.44      0.45      0.44       386\n",
            "weighted avg       0.87      0.86      0.86       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   55.9s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.83      0.89       342\n",
            "           1       0.32      0.63      0.42        43\n",
            "           2       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.81       386\n",
            "   macro avg       0.42      0.49      0.44       386\n",
            "weighted avg       0.87      0.81      0.83       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvCn0iVSWhDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "fd320978-88f1-4728-ae66-2cce159a622b"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "rCSI_df = pd.concat([tz_clust_X_train, tz_clust_y_train['rCSI_category']], axis=1)\n",
        "\n",
        "\n",
        "rCSI_not_crisis = rCSI_df[rCSI_df.rCSI_category==0]\n",
        "rCSI_crisis = rCSI_df[rCSI_df.rCSI_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "rCSI_crisis_upsampled = resample(rCSI_crisis,\n",
        "                                replace=True, # sample with replacement\n",
        "                                n_samples=len(rCSI_not_crisis), # match number in majority class\n",
        "                                random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "rCSI_upsampled = pd.concat([rCSI_not_crisis, rCSI_crisis_upsampled])\n",
        "\n",
        "rCSI_upsampled_y_train = rCSI_upsampled[\"rCSI_category\"]\n",
        "\n",
        "rCSI_upsampled_X_train = rCSI_upsampled.drop(\"rCSI_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (rCSI_upsampled_X_train,rCSI_upsampled_y_train, tz_clust_X_test,tz_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (rCSI_upsampled_X_train,rCSI_upsampled_y_train, tz_clust_X_test,tz_clust_y_test['rCSI_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   25.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.78      0.72       227\n",
            "           1       0.55      0.43      0.49       153\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.63       386\n",
            "   macro avg       0.41      0.40      0.40       386\n",
            "weighted avg       0.61      0.63      0.61       386\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   45.2s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.74      0.70       227\n",
            "           1       0.52      0.44      0.48       153\n",
            "           2       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.61       386\n",
            "   macro avg       0.39      0.39      0.39       386\n",
            "weighted avg       0.59      0.61      0.60       386\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18sfKYpYbAt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "62dd7ee2-e93c-4711-f1b3-1b7bfa7b81f2"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "FCS_df = pd.concat([ug_clust_X_train, ug_clust_y_train['FCS_category']], axis=1)\n",
        "\n",
        "\n",
        "FCS_not_crisis = FCS_df[FCS_df.FCS_category==0]\n",
        "FCS_crisis = FCS_df[FCS_df.FCS_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "FCS_crisis_upsampled = resample(FCS_crisis,\n",
        "                                replace=True, # sample with replacement\n",
        "                                n_samples=len(FCS_not_crisis), # match number in majority class\n",
        "                                random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "FCS_upsampled = pd.concat([FCS_not_crisis, FCS_crisis_upsampled])\n",
        "\n",
        "FCS_upsampled_y_train = FCS_upsampled[\"FCS_category\"]\n",
        "\n",
        "FCS_upsampled_X_train = FCS_upsampled.drop(\"FCS_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (FCS_upsampled_X_train,FCS_upsampled_y_train, ug_clust_X_test,ug_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (FCS_upsampled_X_train,FCS_upsampled_y_train, ug_clust_X_test,ug_clust_y_test['FCS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   14.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.87       334\n",
            "           1       0.44      0.21      0.28        97\n",
            "           2       1.00      0.11      0.20         9\n",
            "\n",
            "    accuracy                           0.76       440\n",
            "   macro avg       0.75      0.42      0.45       440\n",
            "weighted avg       0.73      0.76      0.72       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   14.3s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   32.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.93      0.86       334\n",
            "           1       0.42      0.24      0.30        97\n",
            "           2       0.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.75       440\n",
            "   macro avg       0.41      0.39      0.39       440\n",
            "weighted avg       0.70      0.75      0.72       440\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD3ywclqbFsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "85183715-7b61-4d33-f756-555a798e4171"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "HDDS_df = pd.concat([ug_clust_X_train, ug_clust_y_train['HDDS_category']], axis=1)\n",
        "\n",
        "\n",
        "HDDS_not_crisis = HDDS_df[HDDS_df.HDDS_category==0]\n",
        "HDDS_crisis = HDDS_df[HDDS_df.HDDS_category!=0]\n",
        "\n",
        "# separate minority and majority classes\n",
        "\n",
        "# upsample minority\n",
        "HDDS_crisis_upsampled = resample(HDDS_crisis,\n",
        "                                replace=True, # sample with replacement\n",
        "                                n_samples=len(HDDS_not_crisis), # match number in majority class\n",
        "                                random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "HDDS_upsampled = pd.concat([HDDS_not_crisis, HDDS_crisis_upsampled])\n",
        "\n",
        "HDDS_upsampled_y_train = HDDS_upsampled[\"HDDS_category\"]\n",
        "\n",
        "HDDS_upsampled_X_train = HDDS_upsampled.drop(\"HDDS_category\",axis=1)\n",
        "\n",
        "y_pred,y_test  = rfCLF (HDDS_upsampled_X_train,HDDS_upsampled_y_train, ug_clust_X_test,ug_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "y_pred,y_test  = XGBCLF (HDDS_upsampled_X_train,HDDS_upsampled_y_train, ug_clust_X_test,ug_clust_y_test['HDDS_category'] )\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.8s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    6.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.51      0.43        49\n",
            "           1       0.93      0.89      0.91       389\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.85       440\n",
            "   macro avg       0.43      0.47      0.45       440\n",
            "weighted avg       0.86      0.85      0.85       440\n",
            "\n",
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.73      0.35        49\n",
            "           1       0.95      0.69      0.80       389\n",
            "           2       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.69       440\n",
            "   macro avg       0.39      0.48      0.38       440\n",
            "weighted avg       0.86      0.69      0.75       440\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    3.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpuqtRT6XlkB",
        "colab": {}
      },
      "source": [
        "import imblearn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(ratio='minority')\n",
        "X_sm, y_sm = smote.fit_sample(X, y)\n",
        "\n",
        "sm = SMOTE(random_state=27, ratio=1.0)\n",
        "X_train, y_train = sm.fit_sample(X_train, y_train\n",
        "                                )\n",
        "\n",
        "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "smote_pred = smote.predict(X_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LsdAVsz0XtER"
      },
      "source": [
        "For example, we can cluster the records of the majority class, and do the under-sampling by removing records from each cluster, thus seeking to preserve information. In over-sampling, instead of creating exact copies of the minority class records, we can introduce small variations into those copies, creating more diverse synthetic samples.\n",
        "\n",
        "Let's apply some of these resampling techniques, using the Python library imbalanced-learn. It is compatible with scikit-learn and is part of scikit-learn-contrib projects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MIWQBGxvXz-O",
        "outputId": "59dd548c-dbd3-45bc-c05d-ee09c8c8fbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_classes=2, class_sep=1.5, weights=[0.9, 0.1],\n",
        "    n_informative=3, n_redundant=1, flip_y=0,\n",
        "    n_features=20, n_clusters_per_class=1,\n",
        "    n_samples=100, random_state=10\n",
        ")\n",
        "\n",
        "df = pd.DataFrame(X)\n",
        "df['target'] = y\n",
        "df.target.value_counts().plot(kind='bar', title='Count (target)');\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEFCAYAAADzHRw3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uui299dHYPFa",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler()\n",
        "X_ros, y_ros = ros.fit_sample(X, y)\n",
        "\n",
        "print(X_ros.shape[0] - X.shape[0], 'new random picked points')\n",
        "\n",
        "plot_2d_space(X_ros, y_ros, 'Random over-sampling')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eLUx4gXKYPqN",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "tl = TomekLinks(return_indices=True, ratio='majority')\n",
        "X_tl, y_tl, id_tl = tl.fit_sample(X, y)\n",
        "\n",
        "print('Removed indexes:', id_tl)\n",
        "\n",
        "plot_2d_space(X_tl, y_tl, 'Tomek links under-sampling')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GlGaG-IMZbhA",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(ratio='minority')\n",
        "X_sm, y_sm = smote.fit_sample(X, y)\n",
        "\n",
        "plot_2d_space(X_sm, y_sm, 'SMOTE over-sampling')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pSZuMR4EZfPH",
        "colab": {}
      },
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "smt = SMOTETomek(ratio='auto')\n",
        "X_smt, y_smt = smt.fit_sample(X, y)\n",
        "\n",
        "plot_2d_space(X_smt, y_smt, 'SMOTE + Tomek links')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4LMUHzzLYSdi"
      },
      "source": [
        "Under-sampling: Tomek links\n",
        "Tomek links are pairs of very close instances, but of opposite classes. Removing the instances of the majority class of each pair increases the space between the two classes, facilitating the classification process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h__-JaR3YUXv",
        "colab": {}
      },
      "source": [
        "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
        "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
        "\n",
        "sm = SMOTE(random_state=2)\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
        "\n",
        "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
        "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VwwRHpWtl2rH",
        "colab": {}
      },
      "source": [
        "# confusion matrix , focus on improving the recall rate of the insecure class\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7m2r-MiEmEgQ",
        "colab": {}
      },
      "source": [
        "# One vs all and plot the AUC ( )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MJ3dY58vWSEa"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xchwjtYlnkEv"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YG-4RJ4lhUt0",
        "outputId": "fdfa2008-9f64-45bb-d4b4-278b2fb35cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def fit_linear(X_train, X_test,y_train,y_test):\n",
        "\n",
        "    # Create and fit our linear regression model to training data\n",
        "    model = LinearRegression(fit_intercept=True)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Compute model predictions for test data\n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    r2 = stats.pearsonr(y_test, pred)[0] ** 2\n",
        "    \n",
        "    return r2\n",
        "\n",
        "# implement the algorithm and present results\n",
        "result_table(function=fit_linear)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f60e5263d020>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# implement the algorithm and present results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mresult_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_linear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result_table' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "37T4L-Jrnn-v"
      },
      "source": [
        "#### Ridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vK4myVU3iJrF",
        "outputId": "9c1665a4-38f6-4503-e619-abfc0ec40b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "def fit_ridge(X_train, X_test,y_train,y_test):\n",
        "\n",
        "  model = RidgeCV(alphas=[0.0, 1E-6, 1E-4, 1E-2, 1.0], fit_intercept=True, normalize=True, scoring=None, cv=5, gcv_mode='auto', store_cv_values=False) \n",
        "\n",
        "# Define different alpha values for different fits\n",
        "# alpha = [0.0, 1E-6, 1E-4, 1E-2, 1.0]\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Compute model predictions for test data\n",
        "  pred = model.predict(X_test)\n",
        "\n",
        "  r2 = stats.pearsonr(y_test, pred)[0] ** 2\n",
        "    \n",
        "  return r2\n",
        "\n",
        "\n",
        "\n",
        "# implement the algorithm and present results\n",
        "result_table(function=fit_ridge)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>FCS</th>\n",
              "      <th>HDDS</th>\n",
              "      <th>rCSI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Malawi_household</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malawi_cluster</td>\n",
              "      <td>0.431</td>\n",
              "      <td>0.642</td>\n",
              "      <td>0.217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tanzania_household</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tanzania_cluster</td>\n",
              "      <td>0.153</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uganda_household</td>\n",
              "      <td>0.179</td>\n",
              "      <td>0.219</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Uganda_cluster</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.421</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              dataset    FCS   HDDS   rCSI\n",
              "0    Malawi_household  0.265  0.270  0.110\n",
              "1      Malawi_cluster  0.431  0.642  0.217\n",
              "2  Tanzania_household  0.048  0.006  0.015\n",
              "3    Tanzania_cluster  0.153  0.020  0.087\n",
              "4    Uganda_household  0.179  0.219  0.000\n",
              "5      Uganda_cluster  0.365  0.421  0.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DfaZUtYJiT-g",
        "outputId": "5c8cf6f1-bb78-4097-eb2d-df65188d0454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "def fit_lasso(X_train, X_test,y_train,y_test):\n",
        "\n",
        "    model = LassoCV(eps=0.001, n_alphas=100, alphas=(0.01, 2), fit_intercept=True,precompute='auto',n_jobs=4, random_state=0, selection='cyclic')\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    r2= stats.pearsonr(y_test, pred)[0] ** 2\n",
        "    return r2\n",
        "\n",
        "  \n",
        "# implement the algorithm and present results\n",
        "result_table(function=fit_lasso)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cbfa4d4a02ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# implement the algorithm and present results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mresult_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_lasso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result_table' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cmys1Z7Ojfh-",
        "outputId": "d5e855c6-a528-48cc-ed10-6528111a2fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.linear_model import ElasticNetCV\n",
        "\n",
        "def fit_en(X_train, X_test,y_train,y_test):\n",
        "\n",
        "\n",
        "    model = ElasticNetCV(alphas=(0.1,0.02,3,2), copy_X=True, cv=10, eps=0.004, fit_intercept=True,\n",
        "           l1_ratio=0.33, max_iter=1000, n_alphas=100, n_jobs=1,\n",
        "           normalize=False, positive=False, precompute='auto', random_state=0,\n",
        "           selection='cyclic', tol=0.0001, verbose=0)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    pred = model.predict(X_test)\n",
        "\n",
        "    r2= stats.pearsonr(y_test, pred)[0] ** 2\n",
        "    \n",
        "    return r2\n",
        "\n",
        "\n",
        "# implement the algorithm and present results\n",
        "result_table(function=fit_en)    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>FCS</th>\n",
              "      <th>HDDS</th>\n",
              "      <th>rCSI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Malawi_household</td>\n",
              "      <td>0.377</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malawi_cluster</td>\n",
              "      <td>0.683</td>\n",
              "      <td>0.587</td>\n",
              "      <td>0.192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tanzania_household</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tanzania_cluster</td>\n",
              "      <td>0.153</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uganda_household</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.219</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Uganda_cluster</td>\n",
              "      <td>0.264</td>\n",
              "      <td>0.387</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              dataset    FCS   HDDS   rCSI\n",
              "0    Malawi_household  0.377  0.259  0.094\n",
              "1      Malawi_cluster  0.683  0.587  0.192\n",
              "2  Tanzania_household  0.048  0.005  0.015\n",
              "3    Tanzania_cluster  0.153  0.020  0.088\n",
              "4    Uganda_household  0.141  0.219  0.000\n",
              "5      Uganda_cluster  0.264  0.387  0.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NBViYIF3iJHS",
        "outputId": "339e59ac-6c01-482b-eeac-0948886166e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def fit_rfc(X_train, X_test,y_train,y_test):\n",
        "  # Create Regressor with default properties\n",
        "  rfc = RandomForestRegressor(random_state =0,n_jobs =4,warm_start = True,max_depth=4, min_samples_leaf=5 )\n",
        "  \n",
        "  \n",
        "  parameters = {'max_depth':np.arange( 1,4, 1 ).tolist(), 'min_samples_leaf':np.arange( 1, 4, 1 ).tolist()}\n",
        "  model = GridSearchCV(rfc, parameters,cv=6, n_jobs= 4, iid = True,  refit= True,pre_dispatch= '2*n_jobs')\n",
        "\n",
        "  model.fit(X_train,y_train)\n",
        "  # Fit estimator and display score\n",
        "\n",
        "  # Regress on test data\n",
        "  pred = model.predict(X_test)\n",
        "\n",
        "  r2 = stats.pearsonr(y_test, pred)[0] ** 2\n",
        "    \n",
        "  return r2\n",
        "\n",
        "result_table(function=fit_rfc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>FCS</th>\n",
              "      <th>HDDS</th>\n",
              "      <th>rCSI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Malawi_household</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.269</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Malawi_cluster</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.706</td>\n",
              "      <td>0.267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tanzania_household</td>\n",
              "      <td>0.195</td>\n",
              "      <td>0.221</td>\n",
              "      <td>0.048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tanzania_cluster</td>\n",
              "      <td>0.289</td>\n",
              "      <td>0.385</td>\n",
              "      <td>0.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Uganda_household</td>\n",
              "      <td>0.172</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Uganda_cluster</td>\n",
              "      <td>0.314</td>\n",
              "      <td>0.435</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              dataset    FCS   HDDS   rCSI\n",
              "0    Malawi_household  0.369  0.269  0.115\n",
              "1      Malawi_cluster  0.713  0.706  0.267\n",
              "2  Tanzania_household  0.195  0.221  0.048\n",
              "3    Tanzania_cluster  0.289  0.385  0.127\n",
              "4    Uganda_household  0.172  0.189  0.000\n",
              "5      Uganda_cluster  0.314  0.435  0.000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fz4_Tbc-sZ5q",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Create Regressor with default properties\n",
        "gbr = GradientBoostingRegressor(random_state=0,learning_rate=0.4, n_estimators=9,subsample=1, criterion='friedman_mse', min_samples_split=2)\n",
        "\n",
        "gbr.fit(x_train, y_train_new)\n",
        "pred = gbr.predict(x_test)\n",
        "\n",
        "actual =y_test_new\n",
        "r2_gbr= stats.pearsonr(actual, pred)[0] ** 2\n",
        "r2_gbr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3KqsgrvlszWR",
        "colab": {}
      },
      "source": [
        "from sklearn.gaussian_process import  GaussianProcessRegressor\n",
        "\n",
        "# Import our kernels\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "\n",
        "\n",
        "\n",
        "# Define custom kernel (Matern + noise)\n",
        "krnl = 2. + Matern(length_scale=1, nu=1.8) + WhiteKernel(noise_level=10)\n",
        "\n",
        "# Create Regressor with specified properties\n",
        "gpr = GaussianProcessRegressor(kernel=krnl, random_state=23)\n",
        "\n",
        "# Fit estimator and display score\n",
        "gpr= gpr.fit(x_train, y_train[labels[0]])\n",
        "pred = gpr.predict(x_test)\n",
        "actual = y_test[labels[0]]\n",
        "r2_gpr= stats.pearsonr(actual, pred)[0] ** 2\n",
        "r2_gpr\n",
        "\n",
        "pd = {'svc__C': st.uniform(0, 250),\n",
        "      'svc__gamma': g_vals}\n",
        " \n",
        "# Run randomized search\n",
        "rscv = RandomizedSearchCV(svp, param_distributions=pd,\n",
        "                          n_iter=num_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ANJyTHt4jkT7"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BJC69mEDjhhG",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axs[0, 0].scatter( actual_linear,pred_linear)\n",
        "axs[0, 0].plot(actual_linear,actual_linear, color='red')\n",
        "\n",
        "axs[1, 0].scatter( actual_rfr, pred_rfr)\n",
        "axs[1, 0].plot(actual_rfr, actual_rfr, color='red')\n",
        "\n",
        "\n",
        "axs[0, 1].scatter(actual_en ,pred_en )\n",
        "axs[0, 1].plot(actual_en,actual_en, color='red')\n",
        "\n",
        "axs[1, 1].scatter(actual_gbr, pred_gbr )\n",
        "axs[1, 1].plot(actual_gbr, actual_gbr, color='red')\n",
        "\n",
        "\n",
        "axs[0, 0].title.set_text('Scatter Plot Linear')\n",
        "axs[1, 0].title.set_text('Scatter Plot RandomForest')\n",
        "axs[0, 1].title.set_text('Scatter Plot ElasticNet')\n",
        "axs[1, 1].title.set_text('Scatter Plot GradientBoosting')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WWSlbeogjmtg"
      },
      "source": [
        "## Interpretation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YwonIW4_mEaL",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOGKa1sXYam9"
      },
      "source": [
        "Hit and misses "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IHTFHwnXYbHR",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k0RPD5FsYdVS"
      },
      "source": [
        "expand the prediction to grid level "
      ]
    }
  ]
}